{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8288224,"sourceType":"datasetVersion","datasetId":4923053}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Subset, DataLoader\nimport torchvision\nfrom torch import optim\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nimport torchvision.models as models\n\nimport math\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:26:09.180306Z","iopub.execute_input":"2024-05-03T19:26:09.180685Z","iopub.status.idle":"2024-05-03T19:26:15.697943Z","shell.execute_reply.started":"2024-05-03T19:26:09.180655Z","shell.execute_reply":"2024-05-03T19:26:15.696951Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"eng_characters = [chr(i) for i in range(ord('a'), ord('z')+1)]  # English lowercase letters\neng_characters += [chr(i) for i in range(ord('A'), ord('Z')+1)]  # English uppercase letters\neng_characters += [chr(i) for i in range(ord('0'), ord('9')+1)]  # Digits\neng_characters += ['?','<','>']\n# Add other characters as needed, such as punctuation marks, special symbols, etc.\n\nprint(eng_characters)\n# Define the range of Unicode code points for Telugu characters\nTELUGU_START = 0x0C00\nTELUGU_END = 0x0C7F\n\n# Generate all Telugu characters\ntelugu_characters = [chr(code_point) for code_point in range(TELUGU_START, TELUGU_END + 1)]\ntelugu_characters += ['?','<','>']\n\nprint(telugu_characters)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:26:15.699975Z","iopub.execute_input":"2024-05-03T19:26:15.700735Z","iopub.status.idle":"2024-05-03T19:26:15.709896Z","shell.execute_reply.started":"2024-05-03T19:26:15.700703Z","shell.execute_reply":"2024-05-03T19:26:15.708832Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', '<', '>']\n['ఀ', 'ఁ', 'ం', 'ః', 'ఄ', 'అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ఌ', '\\u0c0d', 'ఎ', 'ఏ', 'ఐ', '\\u0c11', 'ఒ', 'ఓ', 'ఔ', 'క', 'ఖ', 'గ', 'ఘ', 'ఙ', 'చ', 'ఛ', 'జ', 'ఝ', 'ఞ', 'ట', 'ఠ', 'డ', 'ఢ', 'ణ', 'త', 'థ', 'ద', 'ధ', 'న', '\\u0c29', 'ప', 'ఫ', 'బ', 'భ', 'మ', 'య', 'ర', 'ఱ', 'ల', 'ళ', 'ఴ', 'వ', 'శ', 'ష', 'స', 'హ', '\\u0c3a', '\\u0c3b', '\\u0c3c', 'ఽ', 'ా', 'ి', 'ీ', 'ు', 'ూ', 'ృ', 'ౄ', '\\u0c45', 'ె', 'ే', 'ై', '\\u0c49', 'ొ', 'ో', 'ౌ', '్', '\\u0c4e', '\\u0c4f', '\\u0c50', '\\u0c51', '\\u0c52', '\\u0c53', '\\u0c54', 'ౕ', 'ౖ', '\\u0c57', 'ౘ', 'ౙ', 'ౚ', '\\u0c5b', '\\u0c5c', '\\u0c5d', '\\u0c5e', '\\u0c5f', 'ౠ', 'ౡ', 'ౢ', 'ౣ', '\\u0c64', '\\u0c65', '౦', '౧', '౨', '౩', '౪', '౫', '౬', '౭', '౮', '౯', '\\u0c70', '\\u0c71', '\\u0c72', '\\u0c73', '\\u0c74', '\\u0c75', '\\u0c76', '౷', '౸', '౹', '౺', '౻', '౼', '౽', '౾', '౿', '?', '<', '>']\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\ntrain_file = '/kaggle/input/aksharantar2/aksharantar_sampled/tel/tel_train.csv'\nvalid_file = '/kaggle/input/aksharantar2/aksharantar_sampled/tel/tel_valid.csv'\n# Load train and validation datasets\n\n# Load the datasets\ntrain_dataset = pd.read_csv(train_file)\nvalid_dataset = pd.read_csv(valid_file)\n\n# Extract the source and target columns\nsource_data = train_dataset.iloc[:, 0].values\ntarget_data = train_dataset.iloc[:, 1].values\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-03T19:26:15.711454Z","iopub.execute_input":"2024-05-03T19:26:15.711795Z","iopub.status.idle":"2024-05-03T19:26:16.278072Z","shell.execute_reply.started":"2024-05-03T19:26:15.711768Z","shell.execute_reply":"2024-05-03T19:26:16.277082Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"source_data = ['<' + s + '>' for s in source_data]\ntarget_data = ['<' + t + '>' for t in target_data]","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:26:16.280036Z","iopub.execute_input":"2024-05-03T19:26:16.280423Z","iopub.status.idle":"2024-05-03T19:26:16.321065Z","shell.execute_reply.started":"2024-05-03T19:26:16.280386Z","shell.execute_reply":"2024-05-03T19:26:16.320154Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"loc = 1\ne,t = train_dataset.iloc[loc]\nchar_to_index_eng = {char: i for i, char in enumerate(eng_characters)}\nindex_to_char_eng = {i: char for char, i in char_to_index_eng.items()}\ndef char_to_tensor_eng(word, char_to_index_eng):\n    return torch.tensor([char_to_index_eng[char] for char in word], dtype=torch.long)\n\nprint(e)\nprint(char_to_tensor_eng(e,char_to_index_eng))\n\nchar_to_index_tel = {char: i for i, char in enumerate(telugu_characters)}\nindex_to_char_tel = {i: char for char, i in char_to_index_tel.items()}\ndef char_to_tensor_tel(word, char_to_index_tel):\n    return torch.tensor([char_to_index_tel[char] for char in word], dtype=torch.long)\n\nprint(t)\nt1 = char_to_tensor_tel(t,char_to_index_tel)\nprint(t1)\n\ncharacters = [telugu_characters[char_int.item()] for char_int in t1]\nstring = ''.join(characters)\n# Print the characters\nprint(\"Characters:\", string)\n# for batch_idx, (data, target) in enumerate(train_loader):\n#     print(f\"Batch {batch_idx}:\")\n#     print(\"Data shape:\", data.shape)\n#     print(\"Target shape:\", target.shape)\n#     # You can print more details about the data and target if needed\n#     break  # This will break after printing the first batch","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:26:24.862290Z","iopub.execute_input":"2024-05-03T19:26:24.862714Z","iopub.status.idle":"2024-05-03T19:26:24.906087Z","shell.execute_reply.started":"2024-05-03T19:26:24.862682Z","shell.execute_reply":"2024-05-03T19:26:24.905016Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"factamfos\ntensor([ 5,  0,  2, 19,  0, 12,  5, 14, 18])\nఫ్యాక్టమ్ఫోస్\ntensor([43, 77, 47, 62, 21, 77, 31, 46, 77, 43, 75, 56, 77])\nCharacters: ఫ్యాక్టమ్ఫోస్\n","output_type":"stream"}]},{"cell_type":"code","source":"\nsource = [char_to_tensor_eng(s, char_to_index_eng) for s in source_data]\ntarget = [char_to_tensor_tel(s, char_to_index_tel) for s in target_data]","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:26:48.154726Z","iopub.execute_input":"2024-05-03T19:26:48.155144Z","iopub.status.idle":"2024-05-03T19:26:49.516262Z","shell.execute_reply.started":"2024-05-03T19:26:48.155114Z","shell.execute_reply":"2024-05-03T19:26:49.515125Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import TensorDataset\n# Pad the tensors to the same length\n\nsource_padded = pad_sequence(source, batch_first=True, padding_value=62)\ntarget_padded = pad_sequence(target, batch_first=True, padding_value=128)\n\n# Find the maximum length\nmax_length = max(source_padded.size(1), target_padded.size(1))\n\n# Pad source and target to the same length\nsource_padded = torch.nn.functional.pad(source_padded, (0, max_length - source_padded.size(1)), value=62)\ntarget_padded = torch.nn.functional.pad(target_padded, (0, max_length - target_padded.size(1)), value=128)\n\n# Add 62 at the beginning and 63 at the end of each item in source_padded\n# source_padded = torch.cat((torch.full((source_padded.shape[0], 1), 63, dtype=torch.long), \n#                            source_padded, torch.full((source_padded.shape[0], 1), 64, dtype=torch.long)), dim=1)\n# target_padded = torch.cat((torch.full((target_padded.shape[0], 1), 129, dtype=torch.long), \n#                            target_padded, torch.full((target_padded.shape[0], 1), 130, dtype=torch.long)), dim=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:27:00.866662Z","iopub.execute_input":"2024-05-03T19:27:00.867120Z","iopub.status.idle":"2024-05-03T19:27:01.371580Z","shell.execute_reply.started":"2024-05-03T19:27:00.867075Z","shell.execute_reply":"2024-05-03T19:27:01.370225Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-03T17:52:07.896193Z","iopub.execute_input":"2024-05-03T17:52:07.896587Z","iopub.status.idle":"2024-05-03T17:52:07.914443Z","shell.execute_reply.started":"2024-05-03T17:52:07.896558Z","shell.execute_reply":"2024-05-03T17:52:07.913416Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"target_padded[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:27:06.395138Z","iopub.execute_input":"2024-05-03T19:27:06.396102Z","iopub.status.idle":"2024-05-03T19:27:06.405379Z","shell.execute_reply.started":"2024-05-03T19:27:06.396070Z","shell.execute_reply":"2024-05-03T19:27:06.404070Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"tensor([129,  53,  56,  77,  36,  62,  38,  63,  48,  62, 130, 128, 128, 128,\n        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n        128, 128])"},"metadata":{}}]},{"cell_type":"code","source":"def t2p(s,t):\n    characters = [eng_characters[char_int.item()] for char_int in s]\n    string1 = ''.join(characters)\n#     print(string)\n    characters = [telugu_characters[char_int.item()] for char_int in t]\n    string2 = ''.join(characters)\n    print(f\"{string1} {len(string1)} : {string2} {len(string2)} :\")\nt2p(source_padded[0],target_padded[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:27:12.966253Z","iopub.execute_input":"2024-05-03T19:27:12.966640Z","iopub.status.idle":"2024-05-03T19:27:12.975367Z","shell.execute_reply.started":"2024-05-03T19:27:12.966611Z","shell.execute_reply":"2024-05-03T19:27:12.974155Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"<vastadira>??????????????????? 30 : <వస్తాదిరా>??????????????????? 30 :\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a TensorDataset\ndataset = TensorDataset(source_padded, target_padded)\n\n# Create a DataLoader\nbatch_size = 64\ntrain_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Example usage of the DataLoader\ncnt=1\nfor batchid,(s,t) in enumerate(tqdm(train_dataloader)):\n    #source_batch, target_batch = batch\n    # Your training code here\n    print(s[0])\n    for item_s, item_t in zip(s, t):\n#     print(f\"{batchid}:\")\n        t2p(item_s,item_t)\n#     print(s)\n#     cnt+=1\n#     if(cnt>2):break\n    if(batchid>0): break\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:27:18.826081Z","iopub.execute_input":"2024-05-03T19:27:18.827066Z","iopub.status.idle":"2024-05-03T19:27:18.882682Z","shell.execute_reply.started":"2024-05-03T19:27:18.827028Z","shell.execute_reply":"2024-05-03T19:27:18.881479Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"  0%|          | 1/800 [00:00<00:33, 23.82it/s]","output_type":"stream"},{"name":"stdout","text":"tensor([63, 15,  0, 17,  8, 15,  0,  0, 11,  8, 18, 19,  0,  0, 21, 20, 64, 62,\n        62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62])\n<paripaalistaavu>????????????? 30 : <పరిపాలిస్తావు>??????????????? 30 :\n<arisepalli>?????????????????? 30 : <అరిశేపల్లి>?????????????????? 30 :\n<eruganidi>??????????????????? 30 : <ఎరుగనిది>???????????????????? 30 :\n<vayasulokante>??????????????? 30 : <వయసులోకంటే>?????????????????? 30 :\n<belgianlo>??????????????????? 30 : <బెల్జియన్లో>????????????????? 30 :\n<gonjalo>????????????????????? 30 : <గొంజలో>?????????????????????? 30 :\n<alaativaarilo>??????????????? 30 : <అలాటివారిలో>????????????????? 30 :\n<connelly>???????????????????? 30 : <కాన్నేల్లీ>?????????????????? 30 :\n<karrateesukoni>?????????????? 30 : <కర్రతీసుకొని>???????????????? 30 :\n<aarojuraatri>???????????????? 30 : <ఆరోజురాత్రి>????????????????? 30 :\n<marchukosagindi>????????????? 30 : <మార్చుకోసాగింది>????????????? 30 :\n<ananthasubramanian>?????????? 30 : <అనంతసుబ్రహ్మణ్యం>???????????? 30 :\n<pluckias>???????????????????? 30 : <ప్లకియాస్>??????????????????? 30 :\n<talettutondani>?????????????? 30 : <తలెత్తుతోందని>??????????????? 30 :\n<rukminidevigaa>?????????????? 30 : <రుక్మిణిదేవిగా>?????????????? 30 :\n<rasane>?????????????????????? 30 : <రసనే>???????????????????????? 30 :\n<palkiwala>??????????????????? 30 : <పాల్కీవాలా>?????????????????? 30 :\n<vyaktrigata>????????????????? 30 : <వ్యక్త్రిగత>????????????????? 30 :\n<ichchiveyadamto>????????????? 30 : <ఇచ్చివేయడంతో>???????????????? 30 :\n<chadivinchukodaniki>????????? 30 : <చదివించుకోడానికి>???????????? 30 :\n<chesetoniki>????????????????? 30 : <చేసేటోనికి>?????????????????? 30 :\n<nalusupadithe>??????????????? 30 : <నలుసుపడితే>?????????????????? 30 :\n<vaishnavasampradaayamlo>????? 30 : <వైష్ణవసంప్రదాయంలో>??????????? 30 :\n<rgrasati>???????????????????? 30 : <ర్గ్రసతి>???????????????????? 30 :\n<studieslanu>????????????????? 30 : <స్టడీస్లను>?????????????????? 30 :\n<ullaasinulu>????????????????? 30 : <ఉల్లాసినులు>????????????????? 30 :\n<nidaanaanni>????????????????? 30 : <నిదానాన్ని>?????????????????? 30 :\n<suzukila>???????????????????? 30 : <సుజుకీల>????????????????????? 30 :\n<kattesukundama>?????????????? 30 : <కట్టేసుకుందామా>?????????????? 30 :\n<moolamoorthy>???????????????? 30 : <మూలమూర్తి>??????????????????? 30 :\n<tripku>?????????????????????? 30 : <ట్రిప్కు>???????????????????? 30 :\n<jagaranatone>???????????????? 30 : <జాగరణతోనే>??????????????????? 30 :\n<rajakeeyaalnee>?????????????? 30 : <రాజకీయాల్నీ>????????????????? 30 :\n<titteddamanukunna>??????????? 30 : <తిట్టేద్దామనుకున్నా>????????? 30 :\n<dushtatvaalaku>?????????????? 30 : <దుష్టత్వాలకు>???????????????? 30 :\n<bharathudike>???????????????? 30 : <భరతుడికే>???????????????????? 30 :\n<samashtitatvaaniki>?????????? 30 : <సమష్టితత్వానికి>????????????? 30 :\n<bejbaruva>??????????????????? 30 : <బెజ్బరువా>??????????????????? 30 :\n<nakesu>?????????????????????? 30 : <నాకేసు>?????????????????????? 30 :\n<praapanchikamaina>??????????? 30 : <ప్రాపంచికమైన>???????????????? 30 :\n<shids>??????????????????????? 30 : <శిడ్స్>?????????????????????? 30 :\n<gadangi>????????????????????? 30 : <గడంగి>??????????????????????? 30 :\n<maraladu>???????????????????? 30 : <మరలదు>??????????????????????? 30 :\n<oriyooni>???????????????????? 30 : <ఓరియోని>????????????????????? 30 :\n<kurisaayannaaru>????????????? 30 : <కురిశాయన్నారు>??????????????? 30 :\n<prashnaarthakaalatho>???????? 30 : <ప్రశ్నార్థకాలతో>????????????? 30 :\n<durbhalamouta>??????????????? 30 : <దుర్భలమౌట>??????????????????? 30 :\n<potaashiyamlatoe>???????????? 30 : <పొటాషియంలతో>????????????????? 30 :\n<dukkapadutunnaayi>??????????? 30 : <దుఃఖపడుతున్నాయి>????????????? 30 :\n<adavallakuntunda>???????????? 30 : <ఆడవాళ్లకుంటుందా>????????????? 30 :\n<chinnapaarteelaku>??????????? 30 : <చిన్నపార్టీలకు>?????????????? 30 :\n<jagannathaswamiki>??????????? 30 : <జగన్నాథస్వామికి>????????????? 30 :\n<chiruthillaki>??????????????? 30 : <చిరుతిళ్లకి>????????????????? 30 :\n<kotula>?????????????????????? 30 : <కోటుల>??????????????????????? 30 :\n<aayaravindagandhi>??????????? 30 : <ఆయరవిందగంధి>????????????????? 30 :\n<kalavariki>?????????????????? 30 : <కలవారికి>???????????????????? 30 :\n<roopondinchinadenani>???????? 30 : <రూపొందించినదేనని>???????????? 30 :\n<aascharyakaramuu>???????????? 30 : <ఆశ్చర్యకరమూ>????????????????? 30 :\n<saham>??????????????????????? 30 : <సహం>????????????????????????? 30 :\n<stutions>???????????????????? 30 : <స్ట్యూషన్స్>????????????????? 30 :\n<vaadikemichindi>????????????? 30 : <వాడికేమిచ్చింది>????????????? 30 :\n<kesalu>?????????????????????? 30 : <కేసలు>??????????????????????? 30 :\n<marorakamgaanu>?????????????? 30 : <మరోరకంగాను>?????????????????? 30 :\n<pattaabhishiktulayina>??????? 30 : <పట్టాభిషిక్తులయిన>??????????? 30 :\ntensor([63,  3,  0,  2,  7,  4, 18,  4, 13,  3, 20, 10, 20, 64, 62, 62, 62, 62,\n        62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62])\n<dachesenduku>???????????????? 30 : <దాచేసేందుకు>????????????????? 30 :\n<simhaavataaram>?????????????? 30 : <సింహావతారం>?????????????????? 30 :\n<kaabadinaadu>???????????????? 30 : <కాబడినాడు>??????????????????? 30 :\n<bhaaryakuva>????????????????? 30 : <భార్యకువ>???????????????????? 30 :\n<bodhinchaalo>???????????????? 30 : <బోధించాలో>??????????????????? 30 :\n<broyer>?????????????????????? 30 : <బ్రోయర్>????????????????????? 30 :\n<paeshantlaki>???????????????? 30 : <పేశంట్లకి>??????????????????? 30 :\n<shavaalugaane>??????????????? 30 : <శవాలుగానే>??????????????????? 30 :\n<sarichusukovadam>???????????? 30 : <సరిచూసుకోవడం>???????????????? 30 :\n<rajannadi>??????????????????? 30 : <రాజన్నది>???????????????????? 30 :\n<durabhimaanamlo>????????????? 30 : <దురభిమానంలో>????????????????? 30 :\n<kodalugaaru>????????????????? 30 : <కోడలుగారు>??????????????????? 30 :\n<canosa>?????????????????????? 30 : <కనోసా>??????????????????????? 30 :\n<eeyanidi>???????????????????? 30 : <ఈయనిది>?????????????????????? 30 :\n<badhapettayi>???????????????? 30 : <బాధపెట్టాయి>????????????????? 30 :\n<medhanuu>???????????????????? 30 : <మేధనూ>??????????????????????? 30 :\n<chuupinchindamtaa>??????????? 30 : <చూపించిందంతా>???????????????? 30 :\n<swargaadulanu>??????????????? 30 : <స్వర్గాదులను>???????????????? 30 :\n<srikantadatta>??????????????? 30 : <శ్రీకాంతదత్త>???????????????? 30 :\n<evadikenta>?????????????????? 30 : <ఎవడికెంత>???????????????????? 30 :\n<vimarsinchinaadu>???????????? 30 : <విమర్శించినాడు>?????????????? 30 :\n<andhakaaramuloki>???????????? 30 : <అంధకారములోకి>???????????????? 30 :\n<lingamunakedurugaa>?????????? 30 : <లింగమునకెదురుగా>????????????? 30 :\n<baitavallu>?????????????????? 30 : <బైటవాళ్ళు>??????????????????? 30 :\n<hiramgaane>?????????????????? 30 : <హిరంగానే>???????????????????? 30 :\n<kolpoyindi>?????????????????? 30 : <కోల్పొయింది>????????????????? 30 :\n<saadhirachaeraduku>?????????? 30 : <సాధిరచేరదుకు>???????????????? 30 :\n<vippukovataniki>????????????? 30 : <విప్పుకోవటానికి>????????????? 30 :\n<kapalika>???????????????????? 30 : <కపాలిక>?????????????????????? 30 :\n<teliyajeyoddani>????????????? 30 : <తెలియజేయొద్దని>?????????????? 30 :\n<chesukuntunnavu>????????????? 30 : <చేసుకుంటున్నావు>????????????? 30 :\n<lorensz>????????????????????? 30 : <లోరెన్స్జ్>?????????????????? 30 :\n<chrystalize>????????????????? 30 : <క్రిస్టలైజ్>????????????????? 30 :\n<apaarthaalakoo>?????????????? 30 : <అపార్థాలకూ>?????????????????? 30 :\n<ramasmarana>????????????????? 30 : <రామస్మరణ>???????????????????? 30 :\n<vrushabhaanni>??????????????? 30 : <వృషభాన్ని>??????????????????? 30 :\n<armsden>????????????????????? 30 : <ఆర్మ్స్డెన్>????????????????? 30 :\n<pattestaremonani>???????????? 30 : <పట్టేస్తారేమోనని>???????????? 30 :\n<coudate>????????????????????? 30 : <కౌడేట్>?????????????????????? 30 :\n<swaasinchadu>???????????????? 30 : <శ్వాసించదు>?????????????????? 30 :\n<parigettanavasaram>?????????? 30 : <పరిగెత్తనవసరం>??????????????? 30 :\n<aahvaaninchadamto>??????????? 30 : <ఆహ్వానించడంతో>??????????????? 30 :\n<recovery>???????????????????? 30 : <రికవరీ>?????????????????????? 30 :\n<maropramaadam>??????????????? 30 : <మరోప్రమాదం>?????????????????? 30 :\n<nikolayi>???????????????????? 30 : <నికోలాయి>???????????????????? 30 :\n<vanakistunna>???????????????? 30 : <వణకిస్తున్న>????????????????? 30 :\n<tungabhadrapai>?????????????? 30 : <తుంగభద్రపై>?????????????????? 30 :\n<ayidugurutho>???????????????? 30 : <అయిదుగురుతో>????????????????? 30 :\n<totential>??????????????????? 30 : <టోటెన్షియల్>????????????????? 30 :\n<ghatanaasthalaanni>?????????? 30 : <ఘటనాస్థలాన్ని>??????????????? 30 :\n<phiivutunnaaru>?????????????? 30 : <ఫీవుతున్నారు>???????????????? 30 :\n<vikrayinchabadakapothe>?????? 30 : <విక్రయించబడకపోతే>???????????? 30 :\n<koneri>?????????????????????? 30 : <కోనేరి>?????????????????????? 30 :\n<gurainavatilo>??????????????? 30 : <గురైనవాటిలో>????????????????? 30 :\n<varganaijam>????????????????? 30 : <వర్గనైజం>???????????????????? 30 :\n<anandapadatam>??????????????? 30 : <ఆనందపడటం>???????????????????? 30 :\n<suukshmaseedyaanni>?????????? 30 : <సూక్ష్మసేద్యాన్ని>??????????? 30 :\n<pemchaevaatini>?????????????? 30 : <పెంచేవాటిని>????????????????? 30 :\n<thattukovadamlo>????????????? 30 : <తట్టుకోవడంలో>???????????????? 30 :\n<kalugajesukonna>????????????? 30 : <కలుగజేసుకొన్న>??????????????? 30 :\n<aabharanaalunna>????????????? 30 : <ఆభరణాలున్న>?????????????????? 30 :\n<pratikuulatalannitinii>?????? 30 : <ప్రతికూలతలన్నిటినీ>?????????? 30 :\n<rabdomyosarcoma>????????????? 30 : <రాబ్డోమ్యోసార్కోమా>?????????? 30 :\n<suuryunitoonee>?????????????? 30 : <సూర్యునితోనే>???????????????? 30 :\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, num_layers, cell_type):\n        super(Encoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        # Character embedding layer\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        \n        # Encoder RNN\n        if cell_type == 'RNN':\n            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers)\n        elif cell_type == 'LSTM':\n            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers)\n        elif cell_type == 'GRU':\n            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers)\n    \n    def forward(self, x):\n        embedded = self.embedding(x)\n        # embedded shape: (seq_length:max_length, N(batch size:32), embedding_size:100)\n        output, (hidden,cell) = self.rnn(embedded)\n        return hidden,cell\n\nclass Decoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, \n                 output_size, num_layers, cell_type):\n        super(Decoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        # Devanagari character embedding layer\n        self.embedding = nn.Embedding(output_size, embedding_size)\n        \n        # Decoder RNN\n        if cell_type == 'RNN':\n            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers)\n        elif cell_type == 'LSTM':\n            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers)\n        elif cell_type == 'GRU':\n            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers)\n        \n        # Fully connected layer\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x, hidden, cell):\n        # shape of x: (N) but required (1, N)\n        x = x.unsqueeze(0)\n        \n        embedded = self.embedding(x)\n        # embedded shape: (1, N, embedding_size)\n        output, (hidden,cell) = self.rnn(embedded, (hidden,cell))\n        # shape of outputs: (1, N, hidden_size)\n        predictions = self.fc(output)\n        # shape of predictionos:  (1, N, length of tel_char)\n        predictions = predictions.squeeze(0)\n        \n        return predictions, hidden, cell\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n    \n    def forward(self, source, target, teacher_forcing_ratio=0.5):\n        batch_size = source.shape[1]\n        target_len = target.shape[0]\n        target_letter_size = 131\n        \n        outputs = torch.zeros(target_len, batch_size, target_letter_size).to(device)\n        \n        # Encoder forward pass\n        hidden,cell = self.encoder(source)\n        \n        x = target[0]\n        \n#         # Decoder initial hidden state\n#         decoder_hidden = encoder_hidden        \n#         # Decoder input (start token)\n#         decoder_input = torch.tensor([[SOS_token]] * batch_size)      \n        # Decoder forward pass\n    \n        for t in range(1, target_len):\n            output, hidden, cell = self.decoder(x, hidden, cell)\n            outputs[t] = output\n            best_guess = output.argmax(1)\n            x = target[t] if np.random.rand() < teacher_forcing_ratio else best_guess\n        \n        return outputs\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:27:37.173008Z","iopub.execute_input":"2024-05-03T19:27:37.173418Z","iopub.status.idle":"2024-05-03T19:27:37.193576Z","shell.execute_reply.started":"2024-05-03T19:27:37.173388Z","shell.execute_reply":"2024-05-03T19:27:37.192294Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"input_size = len(char_to_index_eng)\nprint(input_size)\nchar_to_index_eng['?']","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:27:42.781388Z","iopub.execute_input":"2024-05-03T19:27:42.782435Z","iopub.status.idle":"2024-05-03T19:27:42.789903Z","shell.execute_reply.started":"2024-05-03T19:27:42.782400Z","shell.execute_reply":"2024-05-03T19:27:42.788578Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"65\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"62"},"metadata":{}}]},{"cell_type":"code","source":"# Define the model architecture\nfrom torch.utils.tensorboard import SummaryWriter\ninput_size = len(char_to_index_eng)\nhidden_size = 300\nembedding_size = 300\noutput_size = len(char_to_index_tel)\nnum_layers = 2\ncell_type = 'LSTM'\nLEARNING_RATE = 0.001\nNUM_EPOCHS = 1\n\nencoder_net = Encoder(input_size, embedding_size, hidden_size, num_layers, cell_type).to(device)\ndecoder_net = Decoder(output_size, embedding_size, hidden_size, \n                 output_size, num_layers, cell_type).to(device)\nmodel = Seq2Seq(encoder_net, decoder_net).to(device)\n\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss(ignore_index = char_to_index_tel['?'])\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\nwriter = SummaryWriter(f'runs/Loss_plot')\nstep = 0\n# Train the model\nfor epoch in range(NUM_EPOCHS):\n    model.train()\n    total_loss = 0\n    for batchid,(inp_data,target) in enumerate(tqdm(train_dataloader)):\n        inp_data = inp_data.to(device)\n        target = target.to(device)\n#         print(inp_data.shape)\n        output = model(inp_data, target)\n        indices = output.argmax(2)\n        # output shape: (trg_len, batch_size, output_dim)\n#         print(output.shape, output.shape[0],output.shape[1], output.shape[2])\n        if(batchid%400==0):\n            t2p(inp_data[0],target[0])\n            t2p(inp_data[0],indices[0])\n            print(indices[0])\n            #print(inp_data.shape, target.shape,output.shape, indices.shape)\n        output = output[1:].reshape(-1, output.shape[2])\n\n        target = target[1:].reshape(-1)\n\n        # Flatten the output and target tensors to compute the loss\n        optimizer.zero_grad()\n        loss = criterion(output, target)\n        total_loss += loss.item()\n\n        # Backpropagation\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=1)\n        optimizer.step()\n        step+=1\n        writer.add_scalar('Training loss', loss, global_step=step)\n\n\n    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_dataloader)}\")\n\n# # Evaluate the model on the validation dataset\n# model.eval()\n# total_val_loss = 0\n# with torch.no_grad():\n#     for input_tensor, target_tensor in valid_loader:\n#         output = model(input_tensor, target_tensor)\n#         output_dim = output.shape[-1]\n\n#         # Flatten the output and target tensors to compute the loss\n#         val_loss = criterion(output.view(-1, output_dim), target_tensor.view(-1))\n#         total_val_loss += val_loss.item()\n\n#     print(f\"Validation Loss: {total_val_loss / len(valid_loader)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:27:47.069543Z","iopub.execute_input":"2024-05-03T19:27:47.070262Z","iopub.status.idle":"2024-05-03T19:29:07.308678Z","shell.execute_reply.started":"2024-05-03T19:27:47.070210Z","shell.execute_reply":"2024-05-03T19:29:07.307650Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"2024-05-03 19:27:49.255332: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-03 19:27:49.255454: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-03 19:27:49.387300: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n  0%|          | 0/800 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"<chudalenemonani>????????????? 30 : <చూడలేనేమోనని>???????????????? 30 :\n<chudalenemonani>????????????? 30 : ఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀ 30 :\ntensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 401/800 [00:34<00:33, 12.07it/s]","output_type":"stream"},{"name":"stdout","text":"<edurupadaalani>?????????????? 30 : <ఎదురుపడాలని>????????????????? 30 :\n<edurupadaalani>?????????????? 30 : ఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀఀ 30 :\ntensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 800/800 [01:08<00:00, 11.70it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 2.911114453077316\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}