{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a010a58c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:04.980861Z",
     "iopub.status.busy": "2024-05-16T10:27:04.980192Z",
     "iopub.status.idle": "2024-05-16T10:27:11.017832Z",
     "shell.execute_reply": "2024-05-16T10:27:11.016850Z"
    },
    "papermill": {
     "duration": 6.04808,
     "end_time": "2024-05-16T10:27:11.020274",
     "exception": false,
     "start_time": "2024-05-16T10:27:04.972194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af61c5a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:11.036293Z",
     "iopub.status.busy": "2024-05-16T10:27:11.035343Z",
     "iopub.status.idle": "2024-05-16T10:27:11.044279Z",
     "shell.execute_reply": "2024-05-16T10:27:11.043372Z"
    },
    "papermill": {
     "duration": 0.019001,
     "end_time": "2024-05-16T10:27:11.046379",
     "exception": false,
     "start_time": "2024-05-16T10:27:11.027378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', '<', '>']\n",
      "['ఀ', 'ఁ', 'ం', 'ః', 'ఄ', 'అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ఌ', '\\u0c0d', 'ఎ', 'ఏ', 'ఐ', '\\u0c11', 'ఒ', 'ఓ', 'ఔ', 'క', 'ఖ', 'గ', 'ఘ', 'ఙ', 'చ', 'ఛ', 'జ', 'ఝ', 'ఞ', 'ట', 'ఠ', 'డ', 'ఢ', 'ణ', 'త', 'థ', 'ద', 'ధ', 'న', '\\u0c29', 'ప', 'ఫ', 'బ', 'భ', 'మ', 'య', 'ర', 'ఱ', 'ల', 'ళ', 'ఴ', 'వ', 'శ', 'ష', 'స', 'హ', '\\u0c3a', '\\u0c3b', '\\u0c3c', 'ఽ', 'ా', 'ి', 'ీ', 'ు', 'ూ', 'ృ', 'ౄ', '\\u0c45', 'ె', 'ే', 'ై', '\\u0c49', 'ొ', 'ో', 'ౌ', '్', '\\u0c4e', '\\u0c4f', '\\u0c50', '\\u0c51', '\\u0c52', '\\u0c53', '\\u0c54', 'ౕ', 'ౖ', '\\u0c57', 'ౘ', 'ౙ', 'ౚ', '\\u0c5b', '\\u0c5c', '\\u0c5d', '\\u0c5e', '\\u0c5f', 'ౠ', 'ౡ', 'ౢ', 'ౣ', '\\u0c64', '\\u0c65', '౦', '౧', '౨', '౩', '౪', '౫', '౬', '౭', '౮', '౯', '\\u0c70', '\\u0c71', '\\u0c72', '\\u0c73', '\\u0c74', '\\u0c75', '\\u0c76', '౷', '౸', '౹', '౺', '౻', '౼', '౽', '౾', '౿', '?', '<', '>']\n"
     ]
    }
   ],
   "source": [
    "eng_characters = [chr(i) for i in range(ord('a'), ord('z')+1)]  # English lowercase letters\n",
    "eng_characters += [chr(i) for i in range(ord('A'), ord('Z')+1)]  # English uppercase letters\n",
    "eng_characters += [chr(i) for i in range(ord('0'), ord('9')+1)]  # Digits\n",
    "eng_characters += ['?','<','>']\n",
    "# Add other characters as needed, such as punctuation marks, special symbols, etc.\n",
    "\n",
    "print(eng_characters)\n",
    "# Define the range of Unicode code points for Telugu characters\n",
    "TELUGU_START = 0x0C00\n",
    "TELUGU_END = 0x0C7F\n",
    "\n",
    "# Generate all Telugu characters\n",
    "telugu_characters = [chr(code_point) for code_point in range(TELUGU_START, TELUGU_END + 1)]\n",
    "telugu_characters += ['?','<','>']\n",
    "\n",
    "print(telugu_characters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435f15d6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:11.060920Z",
     "iopub.status.busy": "2024-05-16T10:27:11.060616Z",
     "iopub.status.idle": "2024-05-16T10:27:11.796997Z",
     "shell.execute_reply": "2024-05-16T10:27:11.796153Z"
    },
    "papermill": {
     "duration": 0.746149,
     "end_time": "2024-05-16T10:27:11.799267",
     "exception": false,
     "start_time": "2024-05-16T10:27:11.053118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_file = '/kaggle/input/aksharantar2/aksharantar_sampled/tel/tel_train.csv'\n",
    "valid_file = '/kaggle/input/aksharantar2/aksharantar_sampled/tel/tel_valid.csv'\n",
    "# Load train and validation datasets\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = pd.read_csv(train_file, header=None)\n",
    "valid_dataset = pd.read_csv(valid_file, header=None)\n",
    "\n",
    "# Extract the source and target columns\n",
    "source_data = train_dataset.iloc[:, 0].values\n",
    "target_data = train_dataset.iloc[:, 1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f95c291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:11.813810Z",
     "iopub.status.busy": "2024-05-16T10:27:11.813019Z",
     "iopub.status.idle": "2024-05-16T10:27:11.846277Z",
     "shell.execute_reply": "2024-05-16T10:27:11.845402Z"
    },
    "papermill": {
     "duration": 0.042507,
     "end_time": "2024-05-16T10:27:11.848207",
     "exception": false,
     "start_time": "2024-05-16T10:27:11.805700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_data = ['<' + s + '>' for s in source_data]\n",
    "target_data = ['<' + t + '>' for t in target_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7296510b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:11.862199Z",
     "iopub.status.busy": "2024-05-16T10:27:11.861892Z",
     "iopub.status.idle": "2024-05-16T10:27:11.897235Z",
     "shell.execute_reply": "2024-05-16T10:27:11.895969Z"
    },
    "papermill": {
     "duration": 0.044657,
     "end_time": "2024-05-16T10:27:11.899218",
     "exception": false,
     "start_time": "2024-05-16T10:27:11.854561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vastadira\n",
      "tensor([21,  0, 18, 19,  0,  3,  8, 17,  0])\n",
      "వస్తాదిరా\n",
      "tensor([53, 56, 77, 36, 62, 38, 63, 48, 62])\n",
      "Characters: వస్తాదిరా\n"
     ]
    }
   ],
   "source": [
    "loc = 1\n",
    "e,t = train_dataset.iloc[loc]\n",
    "char_to_index_eng = {char: i for i, char in enumerate(eng_characters)}\n",
    "index_to_char_eng = {i: char for char, i in char_to_index_eng.items()}\n",
    "def char_to_tensor_eng(word, char_to_index_eng):\n",
    "    return torch.tensor([char_to_index_eng[char] for char in word], dtype=torch.long)\n",
    "\n",
    "print(e)\n",
    "print(char_to_tensor_eng(e,char_to_index_eng))\n",
    "\n",
    "char_to_index_tel = {char: i for i, char in enumerate(telugu_characters)}\n",
    "index_to_char_tel = {i: char for char, i in char_to_index_tel.items()}\n",
    "def char_to_tensor_tel(word, char_to_index_tel):\n",
    "    return torch.tensor([char_to_index_tel[char] for char in word], dtype=torch.long)\n",
    "\n",
    "print(t)\n",
    "t1 = char_to_tensor_tel(t,char_to_index_tel)\n",
    "print(t1)\n",
    "\n",
    "characters = [telugu_characters[char_int.item()] for char_int in t1]\n",
    "string = ''.join(characters)\n",
    "# Print the characters\n",
    "print(\"Characters:\", string)\n",
    "# for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#     print(f\"Batch {batch_idx}:\")\n",
    "#     print(\"Data shape:\", data.shape)\n",
    "#     print(\"Target shape:\", target.shape)\n",
    "#     # You can print more details about the data and target if needed\n",
    "#     break  # This will break after printing the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3231aa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:11.912975Z",
     "iopub.status.busy": "2024-05-16T10:27:11.912670Z",
     "iopub.status.idle": "2024-05-16T10:27:12.989999Z",
     "shell.execute_reply": "2024-05-16T10:27:12.989203Z"
    },
    "papermill": {
     "duration": 1.086694,
     "end_time": "2024-05-16T10:27:12.992232",
     "exception": false,
     "start_time": "2024-05-16T10:27:11.905538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "source = [char_to_tensor_eng(s, char_to_index_eng) for s in source_data]\n",
    "target = [char_to_tensor_tel(s, char_to_index_tel) for s in target_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba4c3e8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:13.006167Z",
     "iopub.status.busy": "2024-05-16T10:27:13.005888Z",
     "iopub.status.idle": "2024-05-16T10:27:13.421908Z",
     "shell.execute_reply": "2024-05-16T10:27:13.420927Z"
    },
    "papermill": {
     "duration": 0.425703,
     "end_time": "2024-05-16T10:27:13.424397",
     "exception": false,
     "start_time": "2024-05-16T10:27:12.998694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset\n",
    "# Pad the tensors to the same length\n",
    "source_padded = pad_sequence(source, batch_first=True, padding_value=62)\n",
    "target_padded = pad_sequence(target, batch_first=True, padding_value=128)\n",
    "\n",
    "# Find the maximum length\n",
    "max_length = max(source_padded.size(1), target_padded.size(1))\n",
    "\n",
    "# Pad source and target to the same length\n",
    "source_padded = torch.nn.functional.pad(source_padded, (0, max_length - source_padded.size(1)), value=62)\n",
    "target_padded = torch.nn.functional.pad(target_padded, (0, max_length - target_padded.size(1)), value=128)\n",
    "\n",
    "# Add 62 at the beginning and 63 at the end of each item in source_padded\n",
    "# source_padded = torch.cat((torch.full((source_padded.shape[0], 1), 63, dtype=torch.long), \n",
    "#                            source_padded, torch.full((source_padded.shape[0], 1), 64, dtype=torch.long)), dim=1)\n",
    "# target_padded = torch.cat((torch.full((target_padded.shape[0], 1), 129, dtype=torch.long), \n",
    "#                            target_padded, torch.full((target_padded.shape[0], 1), 130, dtype=torch.long)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724d7899",
   "metadata": {
    "papermill": {
     "duration": 0.006298,
     "end_time": "2024-05-16T10:27:13.437329",
     "exception": false,
     "start_time": "2024-05-16T10:27:13.431031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31131d48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:13.450643Z",
     "iopub.status.busy": "2024-05-16T10:27:13.450346Z",
     "iopub.status.idle": "2024-05-16T10:27:13.457596Z",
     "shell.execute_reply": "2024-05-16T10:27:13.456688Z"
    },
    "papermill": {
     "duration": 0.01609,
     "end_time": "2024-05-16T10:27:13.459471",
     "exception": false,
     "start_time": "2024-05-16T10:27:13.443381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([129,  53,  48,  77,  23,  62,  50,  53,  62,  48,  63,  40,  71, 130,\n",
       "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "        128, 128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1270391",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:13.473298Z",
     "iopub.status.busy": "2024-05-16T10:27:13.473037Z",
     "iopub.status.idle": "2024-05-16T10:27:13.479501Z",
     "shell.execute_reply": "2024-05-16T10:27:13.478674Z"
    },
    "papermill": {
     "duration": 0.015621,
     "end_time": "2024-05-16T10:27:13.481539",
     "exception": false,
     "start_time": "2024-05-16T10:27:13.465918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<vargaalavaarine>????????????? 30 : <వర్గాలవారినే>???????????????? 30 :\n"
     ]
    }
   ],
   "source": [
    "def t2p(s,t):\n",
    "    characters = [eng_characters[char_int.item()] for char_int in s]\n",
    "    string1 = ''.join(characters)\n",
    "#     print(string)\n",
    "    characters = [telugu_characters[char_int.item()] for char_int in t]\n",
    "    string2 = ''.join(characters)\n",
    "    print(f\"{string1} {len(string1)} : {string2} {len(string2)} :\")\n",
    "t2p(source_padded[0],target_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62019192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:13.495890Z",
     "iopub.status.busy": "2024-05-16T10:27:13.495196Z",
     "iopub.status.idle": "2024-05-16T10:27:13.499728Z",
     "shell.execute_reply": "2024-05-16T10:27:13.498903Z"
    },
    "papermill": {
     "duration": 0.013756,
     "end_time": "2024-05-16T10:27:13.501599",
     "exception": false,
     "start_time": "2024-05-16T10:27:13.487843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(source_padded, target_padded)\n",
    "\n",
    "# Create a DataLoader\n",
    "# batch_size = 64\n",
    "def train_loader(batch_size):\n",
    "    train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return train_dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "603a9539",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:13.515932Z",
     "iopub.status.busy": "2024-05-16T10:27:13.515227Z",
     "iopub.status.idle": "2024-05-16T10:27:13.630381Z",
     "shell.execute_reply": "2024-05-16T10:27:13.629490Z"
    },
    "papermill": {
     "duration": 0.124356,
     "end_time": "2024-05-16T10:27:13.632521",
     "exception": false,
     "start_time": "2024-05-16T10:27:13.508165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#valid_dataset = pd.read_csv(valid_file, header=None)\n",
    "\n",
    "# Extract the source and target columns\n",
    "val_source_data = valid_dataset.iloc[:, 0].values\n",
    "val_target_data = valid_dataset.iloc[:, 1].values\n",
    "\n",
    "val_source_data = ['<' + s + '>' for s in val_source_data]\n",
    "val_target_data = ['<' + t + '>' for t in val_target_data]\n",
    "\n",
    "val_source = [char_to_tensor_eng(s, char_to_index_eng) for s in val_source_data]\n",
    "val_target = [char_to_tensor_tel(s, char_to_index_tel) for s in val_target_data]\n",
    "\n",
    "val_source_padded = pad_sequence(val_source, batch_first=True, padding_value=62)\n",
    "val_target_padded = pad_sequence(val_target, batch_first=True, padding_value=128)\n",
    "\n",
    "# Find the maximum length\n",
    "max_length = max(val_source_padded.size(1), val_target_padded.size(1))\n",
    "\n",
    "# Pad source and target to the same length\n",
    "val_source_padded = torch.nn.functional.pad(val_source_padded, (0, max_length - val_source_padded.size(1)), value=62)\n",
    "val_target_padded = torch.nn.functional.pad(val_target_padded, (0, max_length - val_target_padded.size(1)), value=128)\n",
    "# Create a TensorDataset\n",
    "val_dataset = TensorDataset(val_source_padded, val_target_padded)\n",
    "\n",
    "def val_loader(batch_size):\n",
    "    valid_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    return valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd466a5",
   "metadata": {
    "papermill": {
     "duration": 0.006566,
     "end_time": "2024-05-16T10:27:13.646701",
     "exception": false,
     "start_time": "2024-05-16T10:27:13.640135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5ce4a41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:13.661667Z",
     "iopub.status.busy": "2024-05-16T10:27:13.661387Z",
     "iopub.status.idle": "2024-05-16T10:27:13.681924Z",
     "shell.execute_reply": "2024-05-16T10:27:13.681061Z"
    },
    "papermill": {
     "duration": 0.029692,
     "end_time": "2024-05-16T10:27:13.683826",
     "exception": false,
     "start_time": "2024-05-16T10:27:13.654134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, cell_type, batch_size, dropout_in):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.cell_type = cell_type\n",
    "        self.embeddin_size = embedding_size\n",
    "        self.dropout_in = dropout_in\n",
    "        # Character embedding layer\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        \n",
    "        # Encoder RNN\n",
    "        if cell_type == 'RNN':\n",
    "            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout=dropout_in, batch_first=True)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout_in, batch_first=True)\n",
    "        elif cell_type == 'GRU':\n",
    "            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers, dropout=dropout_in,  batch_first=True)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x)\n",
    "        # embedded shape: (seq_length:max_length, N(batch size:32), embedding_size:100)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        return hidden\n",
    "    \n",
    "    def getInitialState(self):\n",
    "        return torch.zeros(self.num_layers,self.batch_size,self.hidden_size).to(device)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, \n",
    "                 output_size, num_layers, cell_type, dropout_in):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.cell_type = cell_type\n",
    "        self.embeddin_size = embedding_size\n",
    "        self.dropout_in = dropout_in\n",
    "        \n",
    "        # Devanagari character embedding layer\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        \n",
    "        # Decoder RNN\n",
    "        if cell_type == 'RNN':\n",
    "            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout=dropout_in, batch_first=True)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout_in, batch_first=True)\n",
    "        elif cell_type == 'GRU':\n",
    "            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers, dropout=dropout_in,  batch_first=True)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        # shape of x: (N) but required (1, N)\n",
    "#         x = x.unsqueeze(0)\n",
    "        \n",
    "        embedded = self.embedding(x)\n",
    "        # embedded shape: (1, N, embedding_size) #n * 1 * embd\n",
    "        output, hidden = self.rnn(embedded, hidden)  \n",
    "        # shape of outputs: (N*1*131)\n",
    "        predictions = self.softmax(self.fc(output))\n",
    "        # shape of predictionos:  (1, N, length of tel_char)\n",
    "#         predictions = predictions.squeeze(0)\n",
    "\n",
    "        \n",
    "        return predictions, hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, cell_type):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.cell_type = cell_type\n",
    "    \n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "        batch_size = source.shape[0]\n",
    "        target_len = target.shape[1]\n",
    "        target_letter_size = 131\n",
    "#         print(source.shape)\n",
    "#         print(target.shape)\n",
    "        \n",
    "        outputs = torch.zeros(target_len, batch_size, target_letter_size).to(device)\n",
    "        \n",
    "        # Encoder forward pass\n",
    "        if(self.cell_type == \"LSTM\"):\n",
    "            hidden = (self.encoder.getInitialState(), self.encoder.getInitialState())\n",
    "        else:\n",
    "            hidden = self.encoder.getInitialState()\n",
    "#         hidden.to(device)\n",
    "        hidden = self.encoder(source, hidden)\n",
    "        \n",
    "#         print(hidden.shape)\n",
    "        x = target[:,0].view(batch_size, 1)\n",
    "#         print( \"target :\",x.shape)\n",
    "#         print(x)\n",
    "        \n",
    "#         # Decoder initial hidden state\n",
    "#         decoder_hidden = encoder_hidden        \n",
    "#         # Decoder input (start token)\n",
    "#         decoder_input = torch.tensor([[SOS_token]] * batch_size)      \n",
    "        # Decoder forward pass\n",
    "    \n",
    "        for t in range(0, target_len):\n",
    "            output, hidden = self.decoder(x, hidden)\n",
    "            output = output[:, -1, :]\n",
    "            outputs[t] = output\n",
    "            best_guess = output.argmax(1)\n",
    "            best_guess = best_guess.view(batch_size, 1) \n",
    "            x = target[:,t].view(batch_size,1) if np.random.rand() < teacher_forcing_ratio else best_guess\n",
    "        \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80c0c97c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:13.698387Z",
     "iopub.status.busy": "2024-05-16T10:27:13.697767Z",
     "iopub.status.idle": "2024-05-16T10:27:13.703996Z",
     "shell.execute_reply": "2024-05-16T10:27:13.702918Z"
    },
    "papermill": {
     "duration": 0.016117,
     "end_time": "2024-05-16T10:27:13.706392",
     "exception": false,
     "start_time": "2024-05-16T10:27:13.690275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = len(char_to_index_eng)\n",
    "print(input_size)\n",
    "char_to_index_eng['?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5d28627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:13.721043Z",
     "iopub.status.busy": "2024-05-16T10:27:13.720758Z",
     "iopub.status.idle": "2024-05-16T10:27:13.734858Z",
     "shell.execute_reply": "2024-05-16T10:27:13.734049Z"
    },
    "papermill": {
     "duration": 0.023614,
     "end_time": "2024-05-16T10:27:13.736605",
     "exception": false,
     "start_time": "2024-05-16T10:27:13.712991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "input_size = len(char_to_index_eng)\n",
    "output_size = len(char_to_index_tel)\n",
    "# hidden_size = 256\n",
    "# embedding_size = 256\n",
    "# num_layers = 1\n",
    "# cell_type = 'LSTM'\n",
    "# LEARNING_RATE = 0.0001\n",
    "# NUM_EPOCHS = 10\n",
    "\n",
    "def train(hidden_size, embedding_size, \n",
    "          num_layers, cell_type, LEARNING_RATE, NUM_EPOCHS, batch_size, optimizer_in, dropout_in):\n",
    "\n",
    "    train_dataloader = train_loader(batch_size)\n",
    "    valid_dataloader = val_loader(batch_size)\n",
    "    encoder_net = Encoder(input_size, embedding_size, hidden_size, num_layers, cell_type, batch_size, dropout_in).to(device)\n",
    "    decoder_net = Decoder(output_size, embedding_size, hidden_size, \n",
    "                     output_size, num_layers, cell_type, dropout_in).to(device)\n",
    "    model = Seq2Seq(encoder_net, decoder_net, cell_type).to(device)\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    if(optimizer_in == 'adam'):\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    else:\n",
    "        optimizer = optim.Nadam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    step = 0\n",
    "    # Train the model\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        accuracy = 0\n",
    "        for batchid,(inp_data,target) in enumerate(tqdm(train_dataloader)):\n",
    "            inp_data = inp_data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(inp_data, target)\n",
    "            indices = output.argmax(2)\n",
    "\n",
    "            if(batchid==0):\n",
    "                t2p(inp_data[0],target[0])\n",
    "                t2p(inp_data[0],indices[:,0])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = 0\n",
    "            total_correct = 0\n",
    "            for i in range(output.shape[0]):\n",
    "                loss += criterion(output[i], target[:,i])\n",
    "                total_correct += ((indices[:, i] == target[i]).sum().item() == len(target[i]))\n",
    "            total_loss += loss.item()/ len(inp_data[0])\n",
    "            accuracy += total_correct/batch_size\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=1)\n",
    "            optimizer.step()\n",
    "            step+=1\n",
    "\n",
    "        train_loss = total_loss / len(train_dataloader)\n",
    "        train_accuracy = accuracy\n",
    "        validation_loss, validation_accuracy = calculate_validation_loss(model, criterion, valid_dataloader, batch_size)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_dataloader)}\")\n",
    "        print(\"train_acc\", train_accuracy)\n",
    "        print(\"train_loss\", train_loss)\n",
    "        print(\"valid_acc\", validation_accuracy)\n",
    "        print(\"valid_loss\", validation_loss)\n",
    "        \n",
    "        wandb.log({'train_accuracy':train_accuracy})\n",
    "        wandb.log({'train_loss':train_loss})\n",
    "        wandb.log({'val_accuracy':validation_accuracy})\n",
    "        wandb.log({'val_loss':validation_loss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50673d76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:13.751248Z",
     "iopub.status.busy": "2024-05-16T10:27:13.750769Z",
     "iopub.status.idle": "2024-05-16T10:27:13.759826Z",
     "shell.execute_reply": "2024-05-16T10:27:13.759039Z"
    },
    "papermill": {
     "duration": 0.018219,
     "end_time": "2024-05-16T10:27:13.761670",
     "exception": false,
     "start_time": "2024-05-16T10:27:13.743451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_validation_loss(model, criterion, valid_dataloader,batch_size):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_val_loss = 0\n",
    "    accuracy = 0\n",
    "    step = 0\n",
    "    with torch.no_grad():\n",
    "        for batchid,(inp_data,target) in enumerate(tqdm(valid_dataloader)):\n",
    "            inp_data = inp_data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(inp_data, target)\n",
    "            indices = output.argmax(2)\n",
    "            output_dim = output.shape[-1]\n",
    "            if(batchid==0):\n",
    "                t2p(inp_data[0],target[0])\n",
    "                t2p(inp_data[0],indices[:,0])\n",
    "                print((indices[:,0] == target[0]).sum().item())\n",
    "\n",
    "            # Flatten the output and target tensors to compute the loss\n",
    "            val_loss = 0\n",
    "            total_correct = 0\n",
    "            for i in range(output.shape[0]):\n",
    "                val_loss += criterion(output[i], target[:, i])\n",
    "                total_correct += ((indices[:, i] == target[i]).sum().item() == len(target[i]))\n",
    "            step +=1\n",
    "            total_val_loss += val_loss.item() / len(inp_data[0])\n",
    "            accuracy += total_correct/batch_size\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(valid_dataloader)\n",
    "    accuracy = accuracy #/ len(valid_dataloader)\n",
    "    return avg_val_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46bcc5e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:13.776107Z",
     "iopub.status.busy": "2024-05-16T10:27:13.775838Z",
     "iopub.status.idle": "2024-05-16T10:27:13.779368Z",
     "shell.execute_reply": "2024-05-16T10:27:13.778511Z"
    },
    "papermill": {
     "duration": 0.013054,
     "end_time": "2024-05-16T10:27:13.781289",
     "exception": false,
     "start_time": "2024-05-16T10:27:13.768235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train(hidden_size, embedding_size, \n",
    "#           num_layers, cell_type, LEARNING_RATE, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "291d607e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:13.795346Z",
     "iopub.status.busy": "2024-05-16T10:27:13.795090Z",
     "iopub.status.idle": "2024-05-16T10:27:28.928968Z",
     "shell.execute_reply": "2024-05-16T10:27:28.928080Z"
    },
    "papermill": {
     "duration": 15.143129,
     "end_time": "2024-05-16T10:27:28.930976",
     "exception": false,
     "start_time": "2024-05-16T10:27:13.787847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\r\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\r\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\r\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\r\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "wandb.login(key='4823cbdc22dd85ccb0f95f99ade210f09cb97abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b2e583f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:27:28.947915Z",
     "iopub.status.busy": "2024-05-16T10:27:28.947196Z",
     "iopub.status.idle": "2024-05-16T10:27:51.281619Z",
     "shell.execute_reply": "2024-05-16T10:27:51.280575Z"
    },
    "papermill": {
     "duration": 22.344641,
     "end_time": "2024-05-16T10:27:51.283496",
     "exception": false,
     "start_time": "2024-05-16T10:27:28.938855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: pm0g09b5\n",
      "Sweep URL: https://wandb.ai/cs23m005/Assignment3/sweeps/pm0g09b5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nj7eykqo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_in: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m005\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20240516_102730-nj7eykqo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mprime-sweep-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/cs23m005/Assignment3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/cs23m005/Assignment3/sweeps/pm0g09b5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/cs23m005/Assignment3/runs/nj7eykqo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_24/3334400530.py\", line 9, in main_fun\n",
      "    train(params.hidden_size,params.embedding_size,\n",
      "  File \"/tmp/ipykernel_24/2118705626.py\", line 25, in train\n",
      "    optimizer = optim.Nadam(model.parameters(), lr=LEARNING_RATE)\n",
      "AttributeError: module 'torch.optim' has no attribute 'Nadam'. Did you mean: 'NAdam'?\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mprime-sweep-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/cs23m005/Assignment3/runs/nj7eykqo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/cs23m005/Assignment3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240516_102730-nj7eykqo/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run nj7eykqo errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_24/3334400530.py\", line 9, in main_fun\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     train(params.hidden_size,params.embedding_size,\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_24/2118705626.py\", line 25, in train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     optimizer = optim.Nadam(model.parameters(), lr=LEARNING_RATE)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m AttributeError: module 'torch.optim' has no attribute 'Nadam'. Did you mean: 'NAdam'?\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "def main_fun():\n",
    "    wandb.init(project ='Assignment3')\n",
    "    params = wandb.config\n",
    "    with wandb.init(project = 'Assignment3', name='epochs_'+str(params.num_epochs) \n",
    "                    +'layers_'+str(params.num_layers) + 'embedding_'+str(params.embedding_size)\n",
    "                    +'hidden_size_'+str(params.hidden_size) + 'cell_type_'+str(params.cell_type)\n",
    "                    +'lear_rate_'+str(params.learning_rate) + 'batch_size'+str(params.batch_size)\n",
    "                    + 'optim_'+str(params.optimizer) + 'dropout_'+str(params.dropout_in)) as run:\n",
    "        train(params.hidden_size,params.embedding_size,\n",
    "              params.num_layers, params.cell_type, params.learning_rate, \n",
    "              params.num_epochs, params.batch_size,params.optimizer, params.dropout_in)\n",
    "\n",
    "sweep_params = {\n",
    "    'method' : 'bayes',\n",
    "    'name'   : 'cs23m005',\n",
    "    'metric' : {\n",
    "        'goal' : 'maximize',\n",
    "        'name' : 'val_accuracy',\n",
    "    },\n",
    "    'parameters' : {\n",
    "            'num_epochs':{'values':[20,30,40]},\n",
    "            'learning_rate' :{'values':[1e-4, 1e-3]},\n",
    "            'num_layers' :{'values':[1,2,3]},\n",
    "            'embedding_size' :{'values':[64,128,256]},\n",
    "            'hidden_size' :{'values':[64,128,256]},\n",
    "            'cell_type' :{'values':['LSTM', 'GRU', 'RNN']},\n",
    "            'batch_size' :{'values':[64,32,128]},\n",
    "            'optimizer' :{'values':['adam','nadam']},\n",
    "            'dropout_in' :{'values':[0.2,0.3,0.5]}\n",
    "            \n",
    "    }\n",
    "}\n",
    "sweepId = wandb.sweep(sweep_params,project = 'Assignment3')\n",
    "wandb.agent(sweepId,function =main_fun,count = 1)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4923053,
     "sourceId": 8288224,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 51.528876,
   "end_time": "2024-05-16T10:27:53.911932",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-16T10:27:02.383056",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
