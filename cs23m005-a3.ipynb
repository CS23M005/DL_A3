{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8288224,"sourceType":"datasetVersion","datasetId":4923053}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Subset, DataLoader\nimport torchvision\nfrom torch import optim\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nimport torchvision.models as models\n\nimport math\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-05-16T09:53:23.577071Z","iopub.execute_input":"2024-05-16T09:53:23.577927Z","iopub.status.idle":"2024-05-16T09:53:27.831159Z","shell.execute_reply.started":"2024-05-16T09:53:23.577894Z","shell.execute_reply":"2024-05-16T09:53:27.830062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Below code generates the vocabulary for english and telugu\n# For telugu, I have used standard unicode points. Theses points should be changed if used other language \n# start token '<', end token: '>' and pad token: '?'\neng_characters = [chr(i) for i in range(ord('a'), ord('z')+1)]  # English lowercase letters\neng_characters += [chr(i) for i in range(ord('A'), ord('Z')+1)]  # English uppercase letters\neng_characters += [chr(i) for i in range(ord('0'), ord('9')+1)]  # Digits\neng_characters += ['?','<','>']\n\nprint(eng_characters)\n\n\n# Define the range of Unicode code points for Telugu characters\nTELUGU_START = 0x0C00\nTELUGU_END = 0x0C7F\n\n# Generate all Telugu characters\n# start token '<', end token: '>' and pad token: '?'\ntelugu_characters = [chr(code_point) for code_point in range(TELUGU_START, TELUGU_END + 1)]\ntelugu_characters += ['?','<','>']\n\nprint(telugu_characters)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T09:53:27.833043Z","iopub.execute_input":"2024-05-16T09:53:27.833459Z","iopub.status.idle":"2024-05-16T09:53:27.841631Z","shell.execute_reply.started":"2024-05-16T09:53:27.833431Z","shell.execute_reply":"2024-05-16T09:53:27.840693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\ntrain_file = '/kaggle/input/aksharantar2/aksharantar_sampled/tel/tel_train.csv'\nvalid_file = '/kaggle/input/aksharantar2/aksharantar_sampled/tel/tel_valid.csv'\ntest_file = '/kaggle/input/aksharantar2/aksharantar_sampled/tel/tel_test.csv'\n# Load train and validation datasets\n\n# Load the datasets\ntrain_dataset = pd.read_csv(train_file, header=None)\nvalid_dataset = pd.read_csv(valid_file, header=None)\ntest_dataset = pd.read_csv(test_file, header=None)\n\n# Extract the source and target columns\nsource_data = train_dataset.iloc[:, 0].values\ntarget_data = train_dataset.iloc[:, 1].values\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-16T09:53:27.842816Z","iopub.execute_input":"2024-05-16T09:53:27.843629Z","iopub.status.idle":"2024-05-16T09:53:28.285906Z","shell.execute_reply.started":"2024-05-16T09:53:27.843602Z","shell.execute_reply":"2024-05-16T09:53:28.285069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add start and end tokens for each word in the dataset\nsource_data = ['<' + s + '>' for s in source_data]\ntarget_data = ['<' + t + '>' for t in target_data]","metadata":{"execution":{"iopub.status.busy":"2024-05-16T09:53:28.288419Z","iopub.execute_input":"2024-05-16T09:53:28.288720Z","iopub.status.idle":"2024-05-16T09:53:28.325762Z","shell.execute_reply.started":"2024-05-16T09:53:28.288694Z","shell.execute_reply":"2024-05-16T09:53:28.324659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Following code converts input letters to tensors (english and telugu)\nloc = 1\ne,t = train_dataset.iloc[loc]\nchar_to_index_eng = {char: i for i, char in enumerate(eng_characters)}\nindex_to_char_eng = {i: char for char, i in char_to_index_eng.items()}\ndef char_to_tensor_eng(word, char_to_index_eng):\n    return torch.tensor([char_to_index_eng[char] for char in word], dtype=torch.long)\n\nprint(e)\nprint(char_to_tensor_eng(e,char_to_index_eng))\n\nchar_to_index_tel = {char: i for i, char in enumerate(telugu_characters)}\nindex_to_char_tel = {i: char for char, i in char_to_index_tel.items()}\ndef char_to_tensor_tel(word, char_to_index_tel):\n    return torch.tensor([char_to_index_tel[char] for char in word], dtype=torch.long)\n\nprint(t)\nt1 = char_to_tensor_tel(t,char_to_index_tel)\nprint(t1)\n\ncharacters = [telugu_characters[char_int.item()] for char_int in t1]\nstring = ''.join(characters)\n# Print the characters\nprint(\"Characters:\", string)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T09:53:28.326954Z","iopub.execute_input":"2024-05-16T09:53:28.327256Z","iopub.status.idle":"2024-05-16T09:53:28.363654Z","shell.execute_reply.started":"2024-05-16T09:53:28.327231Z","shell.execute_reply":"2024-05-16T09:53:28.362683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Iterate for each word in the dataset\nsource = [char_to_tensor_eng(s, char_to_index_eng) for s in source_data]\ntarget = [char_to_tensor_tel(s, char_to_index_tel) for s in target_data]","metadata":{"execution":{"iopub.status.busy":"2024-05-16T09:53:28.364821Z","iopub.execute_input":"2024-05-16T09:53:28.365107Z","iopub.status.idle":"2024-05-16T09:53:29.528646Z","shell.execute_reply.started":"2024-05-16T09:53:28.365082Z","shell.execute_reply":"2024-05-16T09:53:29.527845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import TensorDataset\n# Pad the tensors to the same length\nsource_padded = pad_sequence(source, batch_first=True, padding_value=62)\ntarget_padded = pad_sequence(target, batch_first=True, padding_value=128)\n\n# Find the maximum length\nmax_length = max(source_padded.size(1), target_padded.size(1))\n\n# Pad source and target to the same length\nsource_padded = torch.nn.functional.pad(source_padded, (0, max_length - source_padded.size(1)), value=62)\ntarget_padded = torch.nn.functional.pad(target_padded, (0, max_length - target_padded.size(1)), value=128)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T09:53:29.529906Z","iopub.execute_input":"2024-05-16T09:53:29.530547Z","iopub.status.idle":"2024-05-16T09:53:29.967848Z","shell.execute_reply.started":"2024-05-16T09:53:29.530512Z","shell.execute_reply":"2024-05-16T09:53:29.967019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Below function converts a given tensor of source, target to english, telugu characters\ndef t2p(s,t):\n    characters = [eng_characters[char_int.item()] for char_int in s]\n    string1 = ''.join(characters)\n#     print(string)\n    characters = [telugu_characters[char_int.item()] for char_int in t]\n    string2 = ''.join(characters)\n    print(f\"{string1} {len(string1)} : {string2} {len(string2)} :\")\nt2p(source_padded[0],target_padded[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-16T09:53:29.978518Z","iopub.execute_input":"2024-05-16T09:53:29.978978Z","iopub.status.idle":"2024-05-16T09:53:29.986272Z","shell.execute_reply.started":"2024-05-16T09:53:29.978946Z","shell.execute_reply":"2024-05-16T09:53:29.985387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a TensorDataset\ndataset = TensorDataset(source_padded, target_padded)\n\n# Create a DataLoader\n# batch_size = 64\ndef train_loader(batch_size):\n    train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    return train_dataloader\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T09:53:29.989633Z","iopub.execute_input":"2024-05-16T09:53:29.989949Z","iopub.status.idle":"2024-05-16T09:53:29.995049Z","shell.execute_reply.started":"2024-05-16T09:53:29.989924Z","shell.execute_reply":"2024-05-16T09:53:29.994033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#valid_dataset = pd.read_csv(valid_file, header=None)\n\n# Extract the source and target columns\nval_source_data = valid_dataset.iloc[:, 0].values\nval_target_data = valid_dataset.iloc[:, 1].values\n\nval_source_data = ['<' + s + '>' for s in val_source_data]\nval_target_data = ['<' + t + '>' for t in val_target_data]\n\nval_source = [char_to_tensor_eng(s, char_to_index_eng) for s in val_source_data]\nval_target = [char_to_tensor_tel(s, char_to_index_tel) for s in val_target_data]\n\nval_source_padded = pad_sequence(val_source, batch_first=True, padding_value=62)\nval_target_padded = pad_sequence(val_target, batch_first=True, padding_value=128)\n\n# Find the maximum length\nmax_length = max(val_source_padded.size(1), val_target_padded.size(1))\n\n# Pad source and target to the same length\nval_source_padded = torch.nn.functional.pad(val_source_padded, (0, max_length - val_source_padded.size(1)), value=62)\nval_target_padded = torch.nn.functional.pad(val_target_padded, (0, max_length - val_target_padded.size(1)), value=128)\n# Create a TensorDataset\nval_dataset = TensorDataset(val_source_padded, val_target_padded)\n\ndef val_loader(batch_size):\n    valid_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n    return valid_dataloader","metadata":{"execution":{"iopub.status.busy":"2024-05-16T09:53:29.996236Z","iopub.execute_input":"2024-05-16T09:53:29.996558Z","iopub.status.idle":"2024-05-16T09:53:30.131134Z","shell.execute_reply.started":"2024-05-16T09:53:29.996506Z","shell.execute_reply":"2024-05-16T09:53:30.130211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Below is the class definitions for Encoder, Decoder, seq2seq module\n# Encoder consists of embedding layer, hidden layers\nclass Encoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, num_layers, cell_type, batch_size, dropout_in):\n        super(Encoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.batch_size = batch_size\n        self.cell_type = cell_type\n        self.embeddin_size = embedding_size\n        self.dropout_in = dropout_in\n        # Character embedding layer\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        \n        # Encoder RNN\n        if cell_type == 'RNN':\n            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout=dropout_in, batch_first=True)\n        elif cell_type == 'LSTM':\n            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout_in, batch_first=True)\n        elif cell_type == 'GRU':\n            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers, dropout=dropout_in,  batch_first=True)\n        \n    def forward(self, x, hidden):\n        embedded = self.embedding(x)\n        # embedded shape: (seq_length:max_length, N(batch size:32), embedding_size:100)\n        output, hidden = self.rnn(embedded, hidden)\n        return hidden\n    \n    def getInitialState(self):\n        return torch.zeros(self.num_layers,self.batch_size,self.hidden_size).to(device)\n\n# Decoder consists of embedding layer, hidden layers and output layer\nclass Decoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, \n                 output_size, num_layers, cell_type, dropout_in):\n        super(Decoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.cell_type = cell_type\n        self.embeddin_size = embedding_size\n        self.dropout_in = dropout_in\n        \n        # Devanagari character embedding layer\n        self.embedding = nn.Embedding(output_size, embedding_size)\n\n        if cell_type == 'RNN':\n            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout=dropout_in, batch_first=True)\n        elif cell_type == 'LSTM':\n            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout_in, batch_first=True)\n        elif cell_type == 'GRU':\n            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers, dropout=dropout_in,  batch_first=True)\n\n        self.fc = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=2)\n    \n    def forward(self, x, hidden):\n        embedded = self.embedding(x)\n        output, hidden = self.rnn(embedded, hidden)  \n        predictions = self.softmax(self.fc(output))       \n        return predictions, hidden\n\n# Following is the class definition for seq2seq module\n# This class uses encoder and decoder module and establishes connection between them\n# It uses default teacher forcing ratio of 0.5. In case of inference, this must be 0 (provision for parameter pass)\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, cell_type):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.cell_type = cell_type\n    \n    def forward(self, source, target, teacher_forcing_ratio=0.5):\n        batch_size = source.shape[0]\n        target_len = target.shape[1]\n        target_letter_size = 131\n        \n        outputs = torch.zeros(target_len, batch_size, target_letter_size).to(device)\n        \n        # Encoder forward pass\n        if(self.cell_type == \"LSTM\"):\n            hidden = (self.encoder.getInitialState(), self.encoder.getInitialState())\n        else:\n            hidden = self.encoder.getInitialState()\n        hidden = self.encoder(source, hidden)    \n        x = target[:,0].view(batch_size, 1)\n\n        # sequentially call the decoder module\n        for t in range(0, target_len):\n            output, hidden = self.decoder(x, hidden)\n            output = output[:, -1, :]\n            outputs[t] = output\n            best_guess = output.argmax(1)\n            best_guess = best_guess.view(batch_size, 1) \n            x = target[:,t].view(batch_size,1) if np.random.rand() < teacher_forcing_ratio else best_guess\n        \n        return outputs\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:14:08.171560Z","iopub.execute_input":"2024-05-16T10:14:08.171951Z","iopub.status.idle":"2024-05-16T10:14:08.197817Z","shell.execute_reply.started":"2024-05-16T10:14:08.171921Z","shell.execute_reply":"2024-05-16T10:14:08.196726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the model architecture\ninput_size = len(char_to_index_eng)\noutput_size = len(char_to_index_tel)\n# hidden_size = 256\n# embedding_size = 256\n# num_layers = 1\n# cell_type = 'LSTM'\n# LEARNING_RATE = 0.0001\n# NUM_EPOCHS = 10\n\n# Following is the train function, that takes the sweep configuration and train the seq2seq model using BP\n\ndef train(hidden_size, embedding_size, \n          num_layers, cell_type, LEARNING_RATE, NUM_EPOCHS, batch_size, optimizer_in, dropout_in):\n\n    train_dataloader = train_loader(batch_size)\n    valid_dataloader = val_loader(batch_size)\n    encoder_net = Encoder(input_size, embedding_size, hidden_size, num_layers, cell_type, batch_size, dropout_in).to(device)\n    decoder_net = Decoder(output_size, embedding_size, hidden_size, \n                     output_size, num_layers, cell_type, dropout_in).to(device)\n    model = Seq2Seq(encoder_net, decoder_net, cell_type).to(device)\n\n    criterion = nn.NLLLoss()\n    if(optimizer_in == 'adam'):\n        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    else:\n        optimizer = optim.NAdam(model.parameters(), lr=LEARNING_RATE)\n\n    step = 0\n    # Train the model\n    for epoch in range(NUM_EPOCHS):\n        model.train()\n        total_loss = 0\n        total_correct = 0\n        accuracy = 0\n        for batchid,(inp_data,target) in enumerate(tqdm(train_dataloader)):\n            inp_data = inp_data.to(device)\n            target = target.to(device)\n\n            output = model(inp_data, target)\n            indices = output.argmax(2)\n\n            if(batchid==0):\n                t2p(inp_data[0],target[0])\n                t2p(inp_data[0],indices[:,0])\n\n            optimizer.zero_grad()\n            loss = 0\n            for i in range(output.shape[0]):\n                loss += criterion(output[i], target[:,i])\n                total_correct += ((indices[:, i] == target[i]).sum().item() == len(target[i]))\n            total_loss += loss.item()/ len(inp_data[0])\n            #accuracy += total_correct/batch_size\n            # Backpropagation\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=1)\n            optimizer.step()\n            step+=1\n\n        train_loss = total_loss / len(train_dataloader)\n        train_accuracy = total_correct/ len(train_dataloader.dataset)\n        validation_loss, validation_accuracy = calculate_validation_loss(model, criterion, valid_dataloader, batch_size)\n        \n        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_dataloader)}\")\n        print(\"train_acc\", train_accuracy)\n        print(\"train_loss\", train_loss)\n        print(\"valid_acc\", validation_accuracy)\n        print(\"valid_loss\", validation_loss)\n        \n        wandb.log({'train_accuracy':train_accuracy})\n        wandb.log({'train_loss':train_loss})\n        wandb.log({'val_accuracy':validation_accuracy})\n        wandb.log({'val_loss':validation_loss})\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T11:03:29.174285Z","iopub.execute_input":"2024-05-16T11:03:29.174651Z","iopub.status.idle":"2024-05-16T11:03:29.190443Z","shell.execute_reply.started":"2024-05-16T11:03:29.174620Z","shell.execute_reply":"2024-05-16T11:03:29.189419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Following is the validation loss/accuracy calculation function\n# teacher forcing must be zero\ndef calculate_validation_loss(model, criterion, valid_dataloader,batch_size):\n    model.eval()  # Set the model to evaluation mode\n    total_val_loss = 0\n    accuracy = 0\n    total_correct = 0\n    step = 0\n    with torch.no_grad():\n        for batchid,(inp_data,target) in enumerate(tqdm(valid_dataloader)):\n            inp_data = inp_data.to(device)\n            target = target.to(device)\n\n            output = model(inp_data, target, 0) # teacher - forcing to 0\n            indices = output.argmax(2)\n            output_dim = output.shape[-1]\n            if(batchid==0):\n                t2p(inp_data[0],target[0])\n                t2p(inp_data[0],indices[:,0])\n                print((indices[:,0] == target[0]).sum().item())\n\n            # Flatten the output and target tensors to compute the loss\n            val_loss = 0\n            \n            for i in range(output.shape[0]):\n                val_loss += criterion(output[i], target[:, i])\n                total_correct += ((indices[:, i] == target[i]).sum().item() == len(target[i]))\n            step +=1\n            total_val_loss += val_loss.item() / len(inp_data[0])\n            #accuracy += total_correct/batch_size\n\n    avg_val_loss = total_val_loss / len(valid_dataloader)\n    accuracy = total_correct/len(valid_dataloader.dataset) #/ len(valid_dataloader)\n    return avg_val_loss, accuracy\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T11:06:14.249879Z","iopub.execute_input":"2024-05-16T11:06:14.250770Z","iopub.status.idle":"2024-05-16T11:06:14.260859Z","shell.execute_reply.started":"2024-05-16T11:06:14.250733Z","shell.execute_reply":"2024-05-16T11:06:14.259831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train(hidden_size, embedding_size, \n#           num_layers, cell_type, LEARNING_RATE, NUM_EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T09:53:30.197170Z","iopub.execute_input":"2024-05-16T09:53:30.197562Z","iopub.status.idle":"2024-05-16T09:53:30.202778Z","shell.execute_reply.started":"2024-05-16T09:53:30.197532Z","shell.execute_reply":"2024-05-16T09:53:30.201883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wandb\nimport wandb\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T09:53:30.203793Z","iopub.execute_input":"2024-05-16T09:53:30.204080Z","iopub.status.idle":"2024-05-16T09:53:58.408681Z","shell.execute_reply.started":"2024-05-16T09:53:30.204057Z","shell.execute_reply":"2024-05-16T09:53:58.407729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def main_fun():\n#     wandb.init(project ='Assignment3')\n#     params = wandb.config\n#     with wandb.init(project = 'Assignment3', name='epochs_'+str(params.num_epochs) \n#                     +'layers_'+str(params.num_layers) + 'embedding_'+str(params.embedding_size)\n#                     +'hidden_size_'+str(params.hidden_size) + 'cell_type_'+str(params.cell_type)\n#                     +'lear_rate_'+str(params.learning_rate) + 'batch_size'+str(params.batch_size)\n#                     + 'optim_'+str(params.optimizer) + 'dropout_'+str(params.dropout_in)) as run:\n#         train(params.hidden_size,params.embedding_size,\n#               params.num_layers, params.cell_type, params.learning_rate, \n#               params.num_epochs, params.batch_size,params.optimizer, params.dropout_in)\n\n# sweep_params = {\n#     'method' : 'bayes',\n#     'name'   : 'cs23m005',\n#     'metric' : {\n#         'goal' : 'maximize',\n#         'name' : 'val_accuracy',\n#     },\n#     'parameters' : {\n#             'num_epochs':{'values':[20,25,30]},\n#             'learning_rate' :{'values':[1e-4, 1e-3]},\n#             'num_layers' :{'values':[1,2,3,4,5]},\n#             'embedding_size' :{'values':[128,256]},\n#             'hidden_size' :{'values':[128,256]},\n#             'cell_type' :{'values':['LSTM', 'GRU', 'RNN']},\n#             'batch_size' :{'values':[64,32,128]},\n#             'optimizer' :{'values':['adam','nadam']},\n#             'dropout_in' :{'values':[0.2,0.3,0.5]}\n            \n#     }\n# }\n# sweepId = wandb.sweep(sweep_params,project = 'Assignment3')\n# wandb.agent(sweepId,function =main_fun,count = 1)\n# wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T11:06:18.619379Z","iopub.execute_input":"2024-05-16T11:06:18.620247Z","iopub.status.idle":"2024-05-16T11:21:28.794314Z","shell.execute_reply.started":"2024-05-16T11:06:18.620213Z","shell.execute_reply":"2024-05-16T11:21:28.793554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import argparse\n\ndef parse_args():\n    p = argparse.ArgumentParser(description = \"provide optinal parameters for training\")\n    p.add_argument('-wp', '--wandb_project', type=str, default=\"Assignment3\", help=\"wandb project name\")\n    p.add_argument('-opt', '--optimizer', type=str, default=\"nadam\", choices = ['adam','nadam'], help=\"optimizer for backprop\")\n    p.add_argument('-bS', '--batch_size', type=int, default=32, choices = [32, 64, 128, 256], help=\"batch size\")\n    p.add_argument('-nE', '--num_epochs', type=int, default=25, choices = [5, 10], help=\"number of epochs\")\n    p.add_argument('-lR', '--learning_rate', type=float, default=1e-3, choices = [1e-3, 1e-4], help=\"learning rate\")\n    p.add_argument('-hS', '--hidden_size', type=int, default=128, choices = [32, 64, 128, 256], help=\"hidden size\")\n    p.add_argument('-eS', '--embedding_size', type=int, default=256, choices = [32, 64, 128, 256], help=\"embedding size\")\n    p.add_argument('-nL', '--num_layers', type=int, default=3, choices = [1,2,3,4,5], help=\"number of layers\")\n    p.add_argument('-cell', '--cell_type', type=str, default=\"LSTM\", choices = ['LSTM', 'GRU', 'RNN'], help=\"cell type\")\n    p.add_argument('-dr', '--dropout_in', type=float, default=0.2, choices = [0,0.2,0.3,0.5], help=\"drop out\")\n    \n\nargs = parse_args()\nwandb.init(project = args.wadb_project)\nwandb.run.name=f'optimizer {str(args.optimizer)} epochs {str(args.num_epochs)} learning rate {args.learning_rate}'\n\ntrain(args.hidden_size,args.embedding_size,\n              args.num_layers, args.cell_type, args.learning_rate, \n              args.num_epochs, args.batch_size,args.optimizer, args.dropout_in)","metadata":{},"execution_count":null,"outputs":[]}]}