{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8288224,"sourceType":"datasetVersion","datasetId":4923053},{"sourceId":8431091,"sourceType":"datasetVersion","datasetId":5020998}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Subset, DataLoader\nimport torchvision\nfrom torch import optim\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nimport torchvision.models as models\n\nimport math\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-05-16T15:36:15.347313Z","iopub.execute_input":"2024-05-16T15:36:15.347671Z","iopub.status.idle":"2024-05-16T15:36:21.843985Z","shell.execute_reply.started":"2024-05-16T15:36:15.347642Z","shell.execute_reply":"2024-05-16T15:36:21.843182Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"eng_characters = [chr(i) for i in range(ord('a'), ord('z')+1)]  # English lowercase letters\neng_characters += [chr(i) for i in range(ord('A'), ord('Z')+1)]  # English uppercase letters\neng_characters += [chr(i) for i in range(ord('0'), ord('9')+1)]  # Digits\neng_characters += ['?','<','>']\n# Add other characters as needed, such as punctuation marks, special symbols, etc.\n\nprint(eng_characters)\n# Define the range of Unicode code points for Telugu characters\nTELUGU_START = 0x0C00\nTELUGU_END = 0x0C7F\n\n# Generate all Telugu characters\ntelugu_characters = [chr(code_point) for code_point in range(TELUGU_START, TELUGU_END + 1)]\ntelugu_characters += ['?','<','>']\n\nprint(telugu_characters)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T15:36:21.845892Z","iopub.execute_input":"2024-05-16T15:36:21.846648Z","iopub.status.idle":"2024-05-16T15:36:21.854938Z","shell.execute_reply.started":"2024-05-16T15:36:21.846612Z","shell.execute_reply":"2024-05-16T15:36:21.853963Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', '<', '>']\n['ఀ', 'ఁ', 'ం', 'ః', 'ఄ', 'అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ఌ', '\\u0c0d', 'ఎ', 'ఏ', 'ఐ', '\\u0c11', 'ఒ', 'ఓ', 'ఔ', 'క', 'ఖ', 'గ', 'ఘ', 'ఙ', 'చ', 'ఛ', 'జ', 'ఝ', 'ఞ', 'ట', 'ఠ', 'డ', 'ఢ', 'ణ', 'త', 'థ', 'ద', 'ధ', 'న', '\\u0c29', 'ప', 'ఫ', 'బ', 'భ', 'మ', 'య', 'ర', 'ఱ', 'ల', 'ళ', 'ఴ', 'వ', 'శ', 'ష', 'స', 'హ', '\\u0c3a', '\\u0c3b', '\\u0c3c', 'ఽ', 'ా', 'ి', 'ీ', 'ు', 'ూ', 'ృ', 'ౄ', '\\u0c45', 'ె', 'ే', 'ై', '\\u0c49', 'ొ', 'ో', 'ౌ', '్', '\\u0c4e', '\\u0c4f', '\\u0c50', '\\u0c51', '\\u0c52', '\\u0c53', '\\u0c54', 'ౕ', 'ౖ', '\\u0c57', 'ౘ', 'ౙ', 'ౚ', '\\u0c5b', '\\u0c5c', '\\u0c5d', '\\u0c5e', '\\u0c5f', 'ౠ', 'ౡ', 'ౢ', 'ౣ', '\\u0c64', '\\u0c65', '౦', '౧', '౨', '౩', '౪', '౫', '౬', '౭', '౮', '౯', '\\u0c70', '\\u0c71', '\\u0c72', '\\u0c73', '\\u0c74', '\\u0c75', '\\u0c76', '౷', '౸', '౹', '౺', '౻', '౼', '౽', '౾', '౿', '?', '<', '>']\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\ntrain_file = '/kaggle/input/aksharantar2/aksharantar_sampled/tel/tel_train.csv'\nvalid_file = '/kaggle/input/aksharantar2/aksharantar_sampled/tel/tel_valid.csv'\n# Load train and validation datasets\n\n# Load the datasets\ntrain_dataset = pd.read_csv(train_file, header=None)\nvalid_dataset = pd.read_csv(valid_file, header=None)\n\n# Extract the source and target columns\nsource_data = train_dataset.iloc[:, 0].values\ntarget_data = train_dataset.iloc[:, 1].values\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-16T15:36:21.856080Z","iopub.execute_input":"2024-05-16T15:36:21.856407Z","iopub.status.idle":"2024-05-16T15:36:22.346391Z","shell.execute_reply.started":"2024-05-16T15:36:21.856377Z","shell.execute_reply":"2024-05-16T15:36:22.345325Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"source_data = ['<' + s + '>' for s in source_data]\ntarget_data = ['<' + t + '>' for t in target_data]","metadata":{"execution":{"iopub.status.busy":"2024-05-16T15:36:22.348466Z","iopub.execute_input":"2024-05-16T15:36:22.349090Z","iopub.status.idle":"2024-05-16T15:36:22.381410Z","shell.execute_reply.started":"2024-05-16T15:36:22.349061Z","shell.execute_reply":"2024-05-16T15:36:22.380430Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"loc = 1\ne,t = train_dataset.iloc[loc]\nchar_to_index_eng = {char: i for i, char in enumerate(eng_characters)}\nindex_to_char_eng = {i: char for char, i in char_to_index_eng.items()}\ndef char_to_tensor_eng(word, char_to_index_eng):\n    return torch.tensor([char_to_index_eng[char] for char in word], dtype=torch.long)\n\nprint(e)\nprint(char_to_tensor_eng(e,char_to_index_eng))\n\nchar_to_index_tel = {char: i for i, char in enumerate(telugu_characters)}\nindex_to_char_tel = {i: char for char, i in char_to_index_tel.items()}\ndef char_to_tensor_tel(word, char_to_index_tel):\n    return torch.tensor([char_to_index_tel[char] for char in word], dtype=torch.long)\n\nprint(t)\nt1 = char_to_tensor_tel(t,char_to_index_tel)\nprint(t1)\n\ncharacters = [telugu_characters[char_int.item()] for char_int in t1]\nstring = ''.join(characters)\n# Print the characters\nprint(\"Characters:\", string)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T15:36:22.382510Z","iopub.execute_input":"2024-05-16T15:36:22.382838Z","iopub.status.idle":"2024-05-16T15:36:22.495745Z","shell.execute_reply.started":"2024-05-16T15:36:22.382799Z","shell.execute_reply":"2024-05-16T15:36:22.494842Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"vastadira\ntensor([21,  0, 18, 19,  0,  3,  8, 17,  0])\nవస్తాదిరా\ntensor([53, 56, 77, 36, 62, 38, 63, 48, 62])\nCharacters: వస్తాదిరా\n","output_type":"stream"}]},{"cell_type":"code","source":"\nsource = [char_to_tensor_eng(s, char_to_index_eng) for s in source_data]\ntarget = [char_to_tensor_tel(s, char_to_index_tel) for s in target_data]","metadata":{"execution":{"iopub.status.busy":"2024-05-16T15:36:22.497384Z","iopub.execute_input":"2024-05-16T15:36:22.498125Z","iopub.status.idle":"2024-05-16T15:36:23.737242Z","shell.execute_reply.started":"2024-05-16T15:36:22.498098Z","shell.execute_reply":"2024-05-16T15:36:23.736452Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import TensorDataset\n# Pad the tensors to the same length\nsource_padded = pad_sequence(source, batch_first=True, padding_value=62)\ntarget_padded = pad_sequence(target, batch_first=True, padding_value=128)\n\n# Find the maximum length\nmax_length = max(source_padded.size(1), target_padded.size(1))\n\n# Pad source and target to the same length\nsource_padded = torch.nn.functional.pad(source_padded, (0, max_length - source_padded.size(1)), value=62)\ntarget_padded = torch.nn.functional.pad(target_padded, (0, max_length - target_padded.size(1)), value=128)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T15:36:23.738461Z","iopub.execute_input":"2024-05-16T15:36:23.739266Z","iopub.status.idle":"2024-05-16T15:36:24.247214Z","shell.execute_reply.started":"2024-05-16T15:36:23.739231Z","shell.execute_reply":"2024-05-16T15:36:24.246356Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def t2p(s,t):\n    characters = [eng_characters[char_int.item()] for char_int in s]\n    string1 = ''.join(characters)\n#     print(string)\n    characters = [telugu_characters[char_int.item()] for char_int in t]\n    string2 = ''.join(characters)\n    print(f\"{string1} {len(string1)} : {string2} {len(string2)} :\")\nt2p(source_padded[0],target_padded[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-16T15:36:24.248458Z","iopub.execute_input":"2024-05-16T15:36:24.248752Z","iopub.status.idle":"2024-05-16T15:36:24.255430Z","shell.execute_reply.started":"2024-05-16T15:36:24.248729Z","shell.execute_reply":"2024-05-16T15:36:24.254552Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"<vargaalavaarine>????????????? 30 : <వర్గాలవారినే>???????????????? 30 :\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a TensorDataset\ndataset = TensorDataset(source_padded, target_padded)\n\n# Create a DataLoader\n# batch_size = 64\ndef train_loader(batch_size):\n    train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    return train_dataloader\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T15:36:24.257017Z","iopub.execute_input":"2024-05-16T15:36:24.257256Z","iopub.status.idle":"2024-05-16T15:36:24.273189Z","shell.execute_reply.started":"2024-05-16T15:36:24.257236Z","shell.execute_reply":"2024-05-16T15:36:24.272506Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#valid_dataset = pd.read_csv(valid_file, header=None)\n\n# Extract the source and target columns\nval_source_data = valid_dataset.iloc[:, 0].values\nval_target_data = valid_dataset.iloc[:, 1].values\n\nval_source_data = ['<' + s + '>' for s in val_source_data]\nval_target_data = ['<' + t + '>' for t in val_target_data]\n\nval_source = [char_to_tensor_eng(s, char_to_index_eng) for s in val_source_data]\nval_target = [char_to_tensor_tel(s, char_to_index_tel) for s in val_target_data]\n\nval_source_padded = pad_sequence(val_source, batch_first=True, padding_value=62)\nval_target_padded = pad_sequence(val_target, batch_first=True, padding_value=128)\n\n# Find the maximum length\nmax_length = max(val_source_padded.size(1), val_target_padded.size(1))\n\n# Pad source and target to the same length\nval_source_padded = torch.nn.functional.pad(val_source_padded, (0, max_length - val_source_padded.size(1)), value=62)\nval_target_padded = torch.nn.functional.pad(val_target_padded, (0, max_length - val_target_padded.size(1)), value=128)\n# Create a TensorDataset\nval_dataset = TensorDataset(val_source_padded, val_target_padded)\n\ndef val_loader(batch_size):\n    valid_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n    return valid_dataloader","metadata":{"execution":{"iopub.status.busy":"2024-05-16T15:36:24.275996Z","iopub.execute_input":"2024-05-16T15:36:24.276256Z","iopub.status.idle":"2024-05-16T15:36:24.416638Z","shell.execute_reply.started":"2024-05-16T15:36:24.276234Z","shell.execute_reply":"2024-05-16T15:36:24.415820Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, hidden_size):\n        super(Attention, self).__init__()\n        self.Wa = nn.Linear(hidden_size, hidden_size)\n        self.Ua = nn.Linear(hidden_size, hidden_size)\n        self.Va = nn.Linear(hidden_size, 1)\n\n    def forward(self, query, keys):\n        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n        scores = scores.squeeze().unsqueeze(1)\n        weights = F.softmax(scores, dim=0)\n        weights = weights.permute(2,1,0)\n        keys = keys.permute(1,0,2)\n        context = torch.bmm(weights, keys)\n        return context, weights\n    \n    \nclass Encoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, num_layers, cell_type, batch_size, dropout_in):\n        super(Encoder, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.batch_size = batch_size\n        self.cell_type = cell_type\n        self.embeddin_size = embedding_size\n        self.dropout_in = dropout_in\n        # Character embedding layer\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        \n        # Encoder RNN\n        if cell_type == 'RNN':\n            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout=dropout_in, batch_first=True)\n        elif cell_type == 'LSTM':\n            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout_in, batch_first=True)\n        elif cell_type == 'GRU':\n            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers, dropout=dropout_in,  batch_first=True)\n    \n    def forward(self, x , encoder_curr_state):\n        encoder_states  = self.getInit()\n        sequenceLength = len(x[0])\n        for i in range(0,sequenceLength):\n            current_input = x[:, i].view(self.batch_size,1)\n            _, encoder_curr_state = self.forward_step(current_input, encoder_curr_state)\n            if(self.cell_type == 'LSTM'):\n                encoder_states[i] = encoder_curr_state[1]\n            else: \n                encoder_states[i] = encoder_curr_state\n        return encoder_states, encoder_curr_state\n    \n    def forward_step(self, x, hidden):\n        embedded = self.embedding(x)\n        output, hidden = self.rnn(embedded, hidden)\n        return output, hidden\n    \n    def getInit(self):\n        return torch.zeros(self.input_size, self.num_layers, self.batch_size, self.hidden_size).to(device)\n    \n    def getInitialState(self):\n        return torch.zeros(self.num_layers,self.batch_size,self.hidden_size).to(device)\n\n\nclass Decoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, \n                 output_size, num_layers, cell_type, dropout_in):\n        super(Decoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.cell_type = cell_type\n        self.embeddin_size = embedding_size\n        self.dropout_in = dropout_in\n        \n        # Devanagari character embedding layer\n        self.embedding = nn.Embedding(output_size, embedding_size)\n        \n        # Decoder RNN\n        if cell_type == 'RNN':\n            self.rnn = nn.RNN(embedding_size+hidden_size, hidden_size, num_layers, dropout=dropout_in, batch_first=True)\n        elif cell_type == 'LSTM':\n            self.rnn = nn.LSTM(embedding_size+hidden_size, hidden_size, num_layers, dropout=dropout_in, batch_first=True)\n        elif cell_type == 'GRU':\n            self.rnn = nn.GRU(embedding_size+hidden_size, hidden_size, num_layers, dropout=dropout_in,  batch_first=True)\n        \n        # Fully connected layer\n        self.fc = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=2)\n        self.dropout = nn.Dropout(dropout_in)\n        self.attention = Attention(hidden_size).to(device)\n    \n    def forward(self, x, hidden, encoder_final_layers):\n        if(self.cell_type == 'LSTM'):\n            context , attn_weights = self.attention(hidden[1][-1,:,:], encoder_final_layers)\n        else:\n            context , attn_weights = self.attention(hidden[-1,:,:], encoder_final_layers)\n\n        embedded = self.embedding(x)\n        curr_embd = F.relu(embedded)\n        input_gru = torch.cat((curr_embd, context), dim=2)\n\n        output, hidden = self.rnn(input_gru, hidden)  \n        output = self.dropout(output)\n        predictions = self.softmax(self.fc(output))\n\n\n        \n        return predictions, hidden, attn_weights\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, cell_type):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.cell_type = cell_type\n    \n    def forward(self, source, target, teacher_forcing_ratio=0.5):\n        batch_size = source.shape[0]\n        target_len = target.shape[1]\n        target_letter_size = 131\n        \n        outputs = torch.zeros(target_len, batch_size, target_letter_size).to(device)\n        \n        if(self.cell_type == \"LSTM\"):\n            hidden = (self.encoder.getInitialState(), self.encoder.getInitialState())\n        else:\n            hidden = self.encoder.getInitialState()\n\n        hidden, encoder_out = self.encoder(source, hidden)\n        decoder_current_state = encoder_out\n        encoder_final_layer_states = hidden[:, -1, :, :]\n        attention = []\n        \n\n        x = target[:,0].view(batch_size, 1)\n    \n        for t in range(0, target_len):\n            decoder_output, decoder_current_state, attention_weights = self.decoder(x, decoder_current_state, \n                                                                           encoder_final_layer_states)\n           \n            decoder_output = decoder_output[:, -1, :]\n            outputs[t] = decoder_output\n            attention.append(attention_weights)\n            best_guess = decoder_output.argmax(1)\n            best_guess = best_guess.view(batch_size, 1) \n            x = target[:,t].view(batch_size,1) if np.random.rand() < teacher_forcing_ratio else best_guess\n        \n        return outputs,attention\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:04:30.918141Z","iopub.execute_input":"2024-05-16T16:04:30.918499Z","iopub.status.idle":"2024-05-16T16:04:30.949286Z","shell.execute_reply.started":"2024-05-16T16:04:30.918470Z","shell.execute_reply":"2024-05-16T16:04:30.948504Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Define the model architecture\ninput_size = len(char_to_index_eng)\noutput_size = len(char_to_index_tel)\n\n\ndef train(hidden_size, embedding_size, \n          num_layers, cell_type, LEARNING_RATE, NUM_EPOCHS, batch_size, optimizer_in, dropout_in):\n\n    train_dataloader = train_loader(batch_size)\n    valid_dataloader = val_loader(batch_size)\n    encoder_net = Encoder(input_size, embedding_size, hidden_size, num_layers, cell_type, batch_size, dropout_in).to(device)\n    decoder_net = Decoder(output_size, embedding_size, hidden_size, \n                     output_size, num_layers, cell_type, dropout_in).to(device)\n    model = Seq2Seq(encoder_net, decoder_net, cell_type).to(device)\n\n    criterion = nn.NLLLoss()\n    if(optimizer_in == 'adam'):\n        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    else:\n        optimizer = optim.NAdam(model.parameters(), lr=LEARNING_RATE)\n\n    step = 0\n    # Train the model\n    for epoch in range(NUM_EPOCHS):\n        model.train()\n        total_loss = 0\n        total_correct = 0\n        accuracy = 0\n        for batchid,(inp_data,target) in enumerate(tqdm(train_dataloader)):\n            inp_data = inp_data.to(device)\n            target = target.to(device)\n\n            output,attention = model(inp_data, target)\n            indices = output.argmax(2)\n\n            if(batchid==0):\n                t2p(inp_data[0],target[0])\n                t2p(inp_data[0],indices[:,0])\n\n            optimizer.zero_grad()\n            loss = 0\n            for i in range(output.shape[0]):\n                loss += criterion(output[i], target[:,i])\n                total_correct += ((indices[:, i] == target[i]).sum().item() == len(target[i]))\n            total_loss += loss.item()/ len(inp_data[0])\n            #accuracy += total_correct/batch_size\n            # Backpropagation\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=1)\n            optimizer.step()\n            step+=1\n\n        train_loss = total_loss / len(train_dataloader)\n        train_accuracy = total_correct/ len(train_dataloader.dataset)\n        validation_loss, validation_accuracy = calculate_validation_loss(model, criterion, valid_dataloader, batch_size)\n        \n        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_dataloader)}\")\n        print(\"train_acc\", train_accuracy)\n        print(\"train_loss\", train_loss)\n        print(\"valid_acc\", validation_accuracy)\n        print(\"valid_loss\", validation_loss)\n        \n        wandb.log({'train_accuracy':train_accuracy})\n        wandb.log({'train_loss':train_loss})\n        wandb.log({'val_accuracy':validation_accuracy})\n        wandb.log({'val_loss':validation_loss})\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:04:27.603154Z","iopub.execute_input":"2024-05-16T16:04:27.603496Z","iopub.status.idle":"2024-05-16T16:04:27.619638Z","shell.execute_reply.started":"2024-05-16T16:04:27.603469Z","shell.execute_reply":"2024-05-16T16:04:27.618814Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def calculate_validation_loss(model, criterion, valid_dataloader,batch_size):\n    model.eval()  # Set the model to evaluation mode\n    total_val_loss = 0\n    accuracy = 0\n    total_correct = 0\n    step = 0\n    with torch.no_grad():\n        for batchid,(inp_data,target) in enumerate(tqdm(valid_dataloader)):\n            inp_data = inp_data.to(device)\n            target = target.to(device)\n\n            output,attention = model(inp_data, target)\n            indices = output.argmax(2)\n            output_dim = output.shape[-1]\n            if(batchid==0):\n                t2p(inp_data[0],target[0])\n                t2p(inp_data[0],indices[:,0])\n                print((indices[:,0] == target[0]).sum().item())\n\n            # Flatten the output and target tensors to compute the loss\n            val_loss = 0\n            \n            for i in range(output.shape[0]):\n                val_loss += criterion(output[i], target[:, i])\n                total_correct += ((indices[:, i] == target[i]).sum().item() == len(target[i]))\n            step +=1\n            total_val_loss += val_loss.item() / len(inp_data[0])\n            #accuracy += total_correct/batch_size\n\n    avg_val_loss = total_val_loss / len(valid_dataloader)\n    accuracy = total_correct/len(valid_dataloader.dataset) #/ len(valid_dataloader)\n    return avg_val_loss, accuracy\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:04:24.290095Z","iopub.execute_input":"2024-05-16T16:04:24.290456Z","iopub.status.idle":"2024-05-16T16:04:24.300965Z","shell.execute_reply.started":"2024-05-16T16:04:24.290427Z","shell.execute_reply":"2024-05-16T16:04:24.299976Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# hidden_size = 64\n# embedding_size = 64\n# num_layers = 1\n# cell_type = 'LSTM'\n# LEARNING_RATE = 0.0001\n# NUM_EPOCHS = 2\n# batch_size = 64\n# optimizer_in = 'adam'\n# dropout_in = 0.5\n# train(hidden_size, embedding_size, \n#           num_layers, cell_type, LEARNING_RATE, NUM_EPOCHS, batch_size, optimizer_in, dropout_in)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T15:55:22.907496Z","iopub.execute_input":"2024-05-16T15:55:22.908314Z","iopub.status.idle":"2024-05-16T15:57:59.651065Z","shell.execute_reply.started":"2024-05-16T15:55:22.908283Z","shell.execute_reply":"2024-05-16T15:57:59.650093Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"  0%|          | 1/800 [00:00<01:21,  9.76it/s]","output_type":"stream"},{"name":"stdout","text":"<edicity>????????????????????? 30 : <ఎడిసిటీ>????????????????????? 30 :\n<edicity>????????????????????? 30 : సస?౏ఉలఉ౵ళ఺?౏౏౏౏౏౏౏౏౏౏౏౏౏౏౏౏౏౏౏ 30 :\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 800/800 [01:16<00:00, 10.49it/s]\n  9%|▉         | 6/64 [00:00<00:02, 28.28it/s]","output_type":"stream"},{"name":"stdout","text":"<bheeshmudini>???????????????? 30 : <భీష్ముడిని>?????????????????? 30 :\n<bheeshmudini>???????????????? 30 : <<్్్్్్్్???????????????????? 30 :\n20\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 64/64 [00:02<00:00, 28.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 1.9425446430842055\ntrain_acc 0.0\ntrain_loss 1.9425446430842055\nvalid_acc 0.0\nvalid_loss 1.1136639356613156\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 1/800 [00:00<01:19,  9.99it/s]","output_type":"stream"},{"name":"stdout","text":"<daivaareeni>????????????????? 30 : <దైవారీని>???????????????????? 30 :\n<daivaareeni>????????????????? 30 : <<్్్్్్>????????????????????? 30 :\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 800/800 [01:15<00:00, 10.53it/s]\n  9%|▉         | 6/64 [00:00<00:02, 28.47it/s]","output_type":"stream"},{"name":"stdout","text":"<bheeshmudini>???????????????? 30 : <భీష్ముడిని>?????????????????? 30 :\n<bheeshmudini>???????????????? 30 : <<్్్్్్్ి>>?????????????????? 30 :\n21\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 64/64 [00:02<00:00, 28.24it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 1.3095762580235797\ntrain_acc 0.0\ntrain_loss 1.3095762580235797\nvalid_acc 0.0\nvalid_loss 1.03423068523407\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install wandb\nimport wandb\nwandb.login(key='4823cbdc22dd85ccb0f95f99ade210f09cb97abc')","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:04:45.211136Z","iopub.execute_input":"2024-05-16T16:04:45.211514Z","iopub.status.idle":"2024-05-16T16:05:03.362485Z","shell.execute_reply.started":"2024-05-16T16:04:45.211486Z","shell.execute_reply":"2024-05-16T16:05:03.361525Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"def main_fun():\n    wandb.init(project ='Assignment3_Attn')\n    params = wandb.config\n    with wandb.init(project = 'Assignment3_Attn', name='epochs_'+str(params.num_epochs) \n                    +'layers_'+str(params.num_layers) + 'embedding_'+str(params.embedding_size)\n                    +'hidden_size_'+str(params.hidden_size) + 'cell_type_'+str(params.cell_type)\n                    +'lear_rate_'+str(params.learning_rate) + 'batch_size'+str(params.batch_size)\n                    + 'optim_'+str(params.optimizer) + 'dropout_'+str(params.dropout_in)) as run:\n        train(params.hidden_size,params.embedding_size,\n              params.num_layers, params.cell_type, params.learning_rate, \n              params.num_epochs, params.batch_size,params.optimizer, params.dropout_in)\n\nsweep_params = {\n    'method' : 'bayes',\n    'name'   : 'cs23m005',\n    'metric' : {\n        'goal' : 'maximize',\n        'name' : 'val_accuracy',\n    },\n    'parameters' : {\n            'num_epochs':{'values':[20,25,30]},\n            'learning_rate' :{'values':[1e-4, 1e-3]},\n            'num_layers' :{'values':[1,2,3,4,5]},\n            'embedding_size' :{'values':[128,256]},\n            'hidden_size' :{'values':[128,256]},\n            'cell_type' :{'values':['LSTM', 'GRU', 'RNN']},\n            'batch_size' :{'values':[64,32,128]},\n            'optimizer' :{'values':['adam','nadam']},\n            'dropout_in' :{'values':[0.2,0.3,0.5]}\n            \n    }\n}\nsweepId = wandb.sweep(sweep_params,project = 'Assignment3_Attn')\nwandb.agent(sweepId,function =main_fun,count = 2)\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:05:09.232180Z","iopub.execute_input":"2024-05-16T16:05:09.232772Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Create sweep with ID: ggyzv1pv\nSweep URL: https://wandb.ai/cs23m005/Assignment3_Attn/sweeps/ggyzv1pv\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5pgaeu0h with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_in: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 30\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m005\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"}]}]}